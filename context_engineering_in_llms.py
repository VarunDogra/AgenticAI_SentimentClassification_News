# -*- coding: utf-8 -*-
"""Context engineering in LLMs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hN8Ze_m4Uvyboq9V6STWwshQWd-_AB7c
"""

# (Full code executed; shortened/annotated here — the workspace has the real executed code.)
import pandas as pd, numpy as np, re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from scipy.sparse import hstack, csr_matrix
from sklearn.model_selection import train_test_split

# 1. Load
#df = pd.read_excel("C:/Users/varun/OneDrive/Documents/Paper/News_Events/News_event_sentiment_labeled.xlsx")

# 2. Parse date, create temporal ordering
df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=False)
df.loc[df['Date_parsed'].isna(),'Date_parsed'] = pd.date_range('2017-01-01', periods=df['Date_parsed'].isna().sum())
df = df.sort_values('Date_parsed').reset_index(drop=True)

# 3. Simple cleaning
def clean_text(s): return re.sub(r'[^a-z0-9\s]',' ', str(s).lower()).strip()
df['text'] = df['News'].apply(clean_text)

# 4. Keyword / context flags (simple emulation of domain rules)
event_triggers = {
    'RBI': ['rbi','repo','rate hike','rate cut','monetary policy'],
    'Ratings': ['rating','downgrade','upgrade','fitch','moodys','s&p'],
    'Fraud': ['fraud','scam','loan fraud','npa','forg'],
    'M&A': ['merger','acquir','takeover'],
    'Results': ['quarter','earnings','profit','loss','results'],
    'Global': ['federal','fed','usd','trade war','commodit'],
    'Governmental': ['budget','election','government','govt','policy']
}
def get_flags(series):
    out=[]
    for t in series:
        row=[]
        for kwlist in event_triggers.values():
            row.append(int(any(kw in t for kw in kwlist)))
        out.append(row)
    return np.array(out)

# 5a. Temporal split (70/15/15) — (the code I used)
n=len(df); train_end=int(0.7*n); val_end=train_end+int(0.15*n)
train_df = df.iloc[:train_end].reset_index(drop=True)
val_df   = df.iloc[train_end:val_end].reset_index(drop=True)
test_df  = df.iloc[val_end:].reset_index(drop=True)

# 5b. Stratified split alternative (recommended for small dataset)
train_df_s, temp_df_s = train_test_split(df, test_size=0.30, random_state=42, stratify=df['Label'])
val_df_s, test_df_s = train_test_split(temp_df_s, test_size=0.5, random_state=42, stratify=temp_df_s['Label'])

# 6. TF-IDF + flags features
tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1,2))
Xtr_tfidf = tfidf.fit_transform(train_df_s['text'])
Xte_tfidf = tfidf.transform(test_df_s['text'])
Xtr_flags = csr_matrix(get_flags(train_df_s['text']))
Xte_flags = csr_matrix(get_flags(test_df_s['text']))
Xtr_prop = hstack([Xtr_tfidf, Xtr_flags])
Xte_prop = hstack([Xte_tfidf, Xte_flags])

# 7. Label encode
le_event = LabelEncoder().fit(df['Label'])
le_sent  = LabelEncoder().fit(df['Sentiment'])
ytr_event = le_event.transform(train_df_s['Label'])
yte_event = le_event.transform(test_df_s['Label'])
ytr_sent  = le_sent.transform(train_df_s['Sentiment'])
yte_sent  = le_sent.transform(test_df_s['Sentiment'])

# 8. Train fast classifiers (MultinomialNB) and evaluate
clf_base_event = MultinomialNB().fit(Xtr_tfidf, ytr_event); ypred_base_event = clf_base_event.predict(Xte_tfidf)
clf_prop_event = MultinomialNB().fit(Xtr_prop, ytr_event); ypred_prop_event = clf_prop_event.predict(Xte_prop)
# same for sentiment...
# 9. Compute metrics: accuracy, micro & macro precision/recall/F1
def metrics(ytrue, ypred):
    acc = accuracy_score(ytrue, ypred)
    prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(ytrue, ypred, average='micro', zero_division=0)
    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(ytrue, ypred, average='macro', zero_division=0)
    return {...}
# Save results to CSV

# 2. Parse date, create temporal ordering
df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce', dayfirst=False)
df.loc[df['Date_parsed'].isna(),'Date_parsed'] = pd.date_range('2017-01-01', periods=df['Date_parsed'].isna().sum())
df = df.sort_values('Date_parsed').reset_index(drop=True)

# 3. Simple cleaning
def clean_text(s): return re.sub(r'[^a-z0-9\s]',' ', str(s).lower()).strip()
df['text'] = df['News'].apply(clean_text)

# 4. Keyword / context flags (simple emulation of domain rules)
event_triggers = {
    'RBI': ['rbi','repo','rate hike','rate cut','monetary policy'],
    'Ratings': ['rating','downgrade','upgrade','fitch','moodys','s&p'],
    'Fraud': ['fraud','scam','loan fraud','npa','forg'],
    'M&A': ['merger','acquir','takeover'],
    'Results': ['quarter','earnings','profit','loss','results'],
    'Global': ['federal','fed','usd','trade war','commodit'],
    'Governmental': ['budget','election','government','govt','policy']
}
def get_flags(series):
    out=[]
    for t in series:
        row=[]
        for kwlist in event_triggers.values():
            row.append(int(any(kw in t for kw in kwlist)))
        out.append(row)
    return np.array(out)

# 5b. Stratified split alternative (recommended for small dataset)
train_df_s, temp_df_s = train_test_split(df, test_size=0.30, random_state=42, stratify=df['Label'])
val_df_s, test_df_s = train_test_split(temp_df_s, test_size=0.5, random_state=42, stratify=temp_df_s['Label'])

# 6. TF-IDF + flags features
tfidf = TfidfVectorizer(max_features=2000, ngram_range=(1,2))
Xtr_tfidf = tfidf.fit_transform(train_df_s['text'])
Xte_tfidf = tfidf.transform(test_df_s['text'])
Xtr_flags = csr_matrix(get_flags(train_df_s['text']))
Xte_flags = csr_matrix(get_flags(test_df_s['text']))
Xtr_prop = hstack([Xtr_tfidf, Xtr_flags])
Xte_prop = hstack([Xte_tfidf, Xte_flags])

# 7. Label encode
le_event = LabelEncoder().fit(df['Label'])
le_sent  = LabelEncoder().fit(df['Sentiment'])
ytr_event = le_event.transform(train_df_s['Label'])
yte_event = le_event.transform(test_df_s['Label'])
ytr_sent  = le_sent.transform(train_df_s['Sentiment'])
yte_sent  = le_sent.transform(test_df_s['Sentiment'])

# 8. Train fast classifiers (MultinomialNB) and evaluate
clf_base_event = MultinomialNB().fit(Xtr_tfidf, ytr_event); ypred_base_event = clf_base_event.predict(Xte_tfidf)
clf_prop_event = MultinomialNB().fit(Xtr_prop, ytr_event); ypred_prop_event = clf_prop_event.predict(Xte_prop)
# same for sentiment...
# 9. Compute metrics: accuracy, micro & macro precision/recall/F1
def metrics(ytrue, ypred):
    acc = accuracy_score(ytrue, ypred)
    prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(ytrue, ypred, average='micro', zero_division=0)
    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(ytrue, ypred, average='macro', zero_division=0)
    return {'accuracy': acc, 'precision_micro': prec_micro, 'recall_micro': rec_micro, 'f1_micro': f1_micro, 'precision_macro': prec_macro, 'recall_macro': rec_macro, 'f1_macro': f1_macro}

# You can now continue with the rest of your code, including training the sentiment model and saving the results.





import io
import pandas as pd
import re
import numpy as np
from google.colab import files

uploaded = files.upload()

file_name = next(iter(uploaded))

# Check if the uploaded file is the expected Excel file
if file_name == "News_event_sentiment_labeled (4).xlsx":
    print(f"File '{file_name}' uploaded successfully.")
    # Now you can read the file using pandas
    df = pd.read_excel(file_name)
    display(df.head())
else:
    print(f"Uploaded file is '{file_name}'. Please upload 'News_event_sentiment_labeled.xlsx'.")

# ------------------------
# Balance dataset for event and sentiment labels
# ------------------------
from sklearn.utils import resample

def balance_dataframe(df, label_col, random_state=SEED):
    """
    Balance the dataset by oversampling minority classes
    separately for the given label column.
    """
    grouped = []
    max_count = df[label_col].value_counts().max()
    for label, group in df.groupby(label_col):
        if len(group) < max_count:
            group_up = resample(group, replace=True, n_samples=max_count, random_state=random_state)
            grouped.append(group_up)
        else:
            grouped.append(group)
    return pd.concat(grouped).sample(frac=1, random_state=random_state).reset_index(drop=True)

# First balance event classes
df_balanced_events = balance_dataframe(df, 'Label')
print("Balanced event classes:", df_balanced_events['Label'].value_counts())

# Then balance sentiment classes (on already event-balanced set)
df_balanced = balance_dataframe(df_balanced_events, 'Sentiment')
print("Balanced sentiment classes:", df_balanced['Sentiment'].value_counts())

# Use this df_balanced for train/val/test splits
df = df_balanced.copy()
print(df.head())

"""
run_experiments.py
Reproducible experiment script for:
Context-Engineered Agentic AI paper — event extraction & sentiment classification
Author: (use your name)
"""

import os
import re
import json
import random
import argparse
import numpy as np
import pandas as pd
from datetime import datetime
from scipy.sparse import hstack, csr_matrix

# sklearn imports
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report

# plotting
import matplotlib.pyplot as plt
import seaborn as sns

# optional: tensorflow for BiLSTM
try:
    import tensorflow as tf
    from tensorflow.keras.models import Model
    from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, GlobalMaxPool1D, GlobalAveragePooling1D, Concatenate
    from tensorflow.keras.preprocessing.text import Tokenizer
    from tensorflow.keras.preprocessing.sequence import pad_sequences
    TF_AVAILABLE = True
except Exception as e:
    TF_AVAILABLE = False
    print("TensorFlow not available - BiLSTM will be skipped. Install tensorflow to enable deep baseline.")

# ------------------------
# Configuration
# ------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)

# File paths (update if necessary)
INPUT_XLSX = "News_event_sentiment_labeled (1).xlsx"  # place the file in same dir or give full path
OUTPUT_DIR = "experiment_outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Experiment settings
SPLIT_MODE = "stratified"  # choose 'temporal' or 'stratified'
TEST_SIZE = 0.30  # used for stratified splitting (makes test+val 30%)
VAL_RATIO_WITHIN_TEMP = 0.5  # when splitting temp into val/test (50/50 => 15% each)
TFIDF_MAX_FEATURES = 3000
SEQUENCE_MAX_LEN = 200      # for BiLSTM if used
EMBEDDING_DIM = 100         # embedding size for BiLSTM (train from scratch)
BATCH_SIZE = 32
EPOCHS = 50                  # small dataset -> fewer epochs, use early stopping if desired

# ------------------------
# Helper functions
# ------------------------
def clean_text(s):
    s = "" if pd.isna(s) else str(s)
    s = s.lower()
    s = re.sub(r'\s+', ' ', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    return s.strip()

def keyword_flags(series, triggers):
    rows = []
    for text in series:
        text = clean_text(text)
        row = []
        for kw_list in triggers.values():
            found = 0
            # Ensure each element in kw_list is treated as a string
            if any(str(kw) in text for kw in kw_list):
                found = 1
            row.append(found)
        rows.append(row)
    return np.array(rows, dtype=int)

def compute_metrics(y_true, y_pred, label_names=None):
    acc = accuracy_score(y_true, y_pred)
    prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)
    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)
    return {
        'accuracy': acc,
        'micro_precision': prec_micro, 'micro_recall': rec_micro, 'micro_f1': f1_micro,
        'macro_precision': prec_macro, 'macro_recall': rec_macro, 'macro_f1': f1_macro
    }

def print_and_save_report(y_true, y_pred, le, fname_prefix):
    labels = list(le.classes_)
    report = classification_report(y_true, y_pred, target_names=labels, zero_division=0)
    cm = confusion_matrix(y_true, y_pred)
    with open(os.path.join(OUTPUT_DIR, f"{fname_prefix}_class_report.txt"), 'w') as f:
        f.write(report)
    pd.DataFrame(cm, index=labels, columns=labels).to_csv(os.path.join(OUTPUT_DIR, f"{fname_prefix}_confusion_matrix.csv"))
    print(report)

def plot_confusion_matrix(y_true, y_pred, labels, title, fname):
    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))
    plt.figure(figsize=(8,6))
    sns.heatmap(cm, annot=True, fmt="d", xticklabels=labels, yticklabels=labels, cmap="Blues")
    plt.title(title)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.tight_layout()
    plt.savefig(os.path.join(OUTPUT_DIR, fname))
    plt.close()

# ------------------------
# Domain triggers (minimal prototype)
# ------------------------
EVENT_TRIGGERS = {
    'RBI': ['rbi','repo','rate hike','rate cut','monetary policy','reverse repo'],
    'Ratings': ['rating','downgrade','upgrade','fitch','moodys','s&p','credit rating'],
    'Fraud': ['fraud','scam','loan fraud','forg','npa','forged','forgery'],
    'M&A': ['merger','acquir','takeover','consolidat'],
    'Results': ['quarter','q1','q2','q3','q4','earnings','profit','loss','results','revenue'],
    'Global': ['fed','federal reserve','usd','usd-inr','trade war','commodit','us fed'],
    'Governmental': ['budget','election','government','govt','policy','fiscal','budget']
}
# ------------------------
# Dynamic trigger generation
# ------------------------
from collections import defaultdict
from sklearn.feature_extraction.text import CountVectorizer

def generate_event_triggers(df, label_col='Label', text_col='News', top_k=10):
    """
    Automatically generate event triggers (keywords) for each event class
    based on most frequent terms in that class.
    """
    triggers = defaultdict(list)
    vectorizer = CountVectorizer(max_features=5000, stop_words='english')
    X = vectorizer.fit_transform(df[text_col].apply(clean_text))
    vocab = np.array(vectorizer.get_feature_names_out())

    for label in df[label_col].unique():
        subset = df[df[label_col] == label]
        X_sub = vectorizer.transform(subset[text_col].apply(clean_text))
        word_freq = np.array(X_sub.sum(axis=0)).flatten()
        top_indices = word_freq.argsort()[-top_k:][::-1]  # top K frequent terms
        triggers[label] = vocab[top_indices].tolist()

    return dict(triggers)


# ------------------------
# Main pipeline
# ------------------------
def main():
    # Load
    assert os.path.exists(INPUT_XLSX), f"Input file not found: {INPUT_XLSX}"
    df = pd.read_excel(INPUT_XLSX)
    print("Loaded:", df.shape, "columns:", df.columns.tolist())

    # Minimal sanity checks
    assert 'News' in df.columns and 'Label' in df.columns and 'Sentiment' in df.columns, "Expected columns: News, Label, Sentiment"

    # Clean
    df['News_clean'] = df['News'].apply(clean_text)

    # Parse dates if available
    if 'Date' in df.columns:
        df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce')
        # fill missing with sequential dates (only if necessary)
        if df['Date_parsed'].isna().sum() > 0:
            df.loc[df['Date_parsed'].isna(), 'Date_parsed'] = pd.date_range(start='2017-01-01', periods=df['Date_parsed'].isna().sum(), freq='D')
    else:
        df['Date_parsed'] = pd.date_range(start='2017-01-01', periods=len(df), freq='D')


    # Encode labels
    le_event = LabelEncoder().fit(df['Label'].astype(str))
    le_sent = LabelEncoder().fit(df['Sentiment'].astype(str))

    # Splits
    if SPLIT_MODE == 'temporal':
        df = df.sort_values('Date_parsed').reset_index(drop=True)
        n = len(df)
        train_end = int(0.70 * n)
        val_end = train_end + int(0.15 * n)
        train_df = df.iloc[:train_end].reset_index(drop=True)
        val_df = df.iloc[train_end:val_end].reset_index(drop=True)
        test_df = df.iloc[val_end:].reset_index(drop=True)
        print("Temporal split sizes:", len(train_df), len(val_df), len(test_df))
    else:
        # stratified split (recommended for small datasets demo)
        train_df, temp_df = train_test_split(df, test_size=TEST_SIZE, random_state=SEED, stratify=df['Label'])
        val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['Label'])
        print("Stratified split sizes:", len(train_df), len(val_df), len(test_df))

    # Feature engineering: TF-IDF
    tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=(1,2))
    X_train_tfidf = tfidf.fit_transform(train_df['News_clean'])
    X_val_tfidf = tfidf.transform(val_df['News_clean'])
    X_test_tfidf = tfidf.transform(test_df['News_clean'])

    # Context flags (domain rules)
    # Generate dynamic event triggers from training set
    EVENT_TRIGGERS = generate_event_triggers(train_df, label_col='Label', text_col='News', top_k=8)
    print("Dynamic EVENT_TRIGGERS generated:", json.dumps(EVENT_TRIGGERS, indent=2))

    # Context flags (dynamic triggers)
    X_train_flags = csr_matrix(keyword_flags(train_df['News'], EVENT_TRIGGERS))
    X_val_flags = csr_matrix(keyword_flags(val_df['News'], EVENT_TRIGGERS))
    X_test_flags = csr_matrix(keyword_flags(test_df['News'], EVENT_TRIGGERS))



    # Proposed concatenated features
    X_train_prop = hstack([X_train_tfidf, X_train_flags])
    X_val_prop = hstack([X_val_tfidf, X_val_flags])
    X_test_prop = hstack([X_test_tfidf, X_test_flags])

    # Labels numeric
    y_train_event = le_event.transform(train_df['Label'].astype(str))
    y_val_event = le_event.transform(val_df['Label'].astype(str))
    y_test_event = le_event.transform(test_df['Label'].astype(str))

    y_train_sent = le_sent.transform(train_df['Sentiment'].astype(str))
    y_val_sent = le_sent.transform(val_df['Sentiment'].astype(str))
    y_test_sent = le_sent.transform(test_df['Sentiment'].astype(str))

    # -------------------------
    # Baselines: MultinomialNB on TF-IDF
    # -------------------------
    print("\nTraining baseline (MultinomialNB) on TF-IDF...")
    base_event_clf = MultinomialNB()
    base_event_clf.fit(X_train_tfidf, y_train_event)
    ypred_event_base = base_event_clf.predict(X_test_tfidf)

    base_sent_clf = MultinomialNB()
    base_sent_clf.fit(X_train_tfidf, y_train_sent)
    ypred_sent_base = base_sent_clf.predict(X_test_tfidf)


    # -------------------------
    # Proposed: MultinomialNB on TF-IDF + flags (simulating context-engineered features)
    # -------------------------
    print("Training proposed (MultinomialNB) on TF-IDF + flags...")
    prop_event_clf = MultinomialNB()
    prop_event_clf.fit(X_train_prop, y_train_event)
    ypred_event_prop = prop_event_clf.predict(X_test_prop)

    prop_sent_clf = MultinomialNB()
    prop_sent_clf.fit(X_train_prop, y_train_sent)
    ypred_sent_prop = prop_sent_clf.predict(X_test_prop)


    # -------------------------
    # Metrics & save summaries
    # -------------------------
    ev_base_metrics = compute_metrics(y_test_event, ypred_event_base)
    ev_prop_metrics = compute_metrics(y_test_event, ypred_event_prop)
    sent_base_metrics = compute_metrics(y_test_sent, ypred_sent_base)
    sent_prop_metrics = compute_metrics(y_test_sent, ypred_sent_prop)


    results = {
        'event_baseline': ev_base_metrics,
        'event_proposed': ev_prop_metrics,
        'sent_baseline': sent_base_metrics,
        'sent_proposed': sent_prop_metrics
    }
    results_df = pd.DataFrame({k: v for k, v in results.items()}).T
    results_df.to_csv(os.path.join(OUTPUT_DIR, "experiment_results_summary.csv"))
    print("\nSaved experiment summary to:", os.path.join(OUTPUT_DIR, "experiment_results_summary.csv"))
    print(results_df.round(3))

    # Save test predictions for qualitative analysis
    test_df_out = test_df.copy()
    test_df_out['pred_event_base'] = le_event.inverse_transform(ypred_event_base)
    test_df_out['pred_event_prop'] = le_event.inverse_transform(ypred_event_prop)
    test_df_out['pred_sent_base'] = le_sent.inverse_transform(ypred_sent_base)
    test_df_out['pred_sent_prop'] = le_sent.inverse_transform(ypred_sent_prop)
    test_df_out.to_csv(os.path.join(OUTPUT_DIR, "test_predictions.csv"), index=False)
    print("Saved test predictions to:", os.path.join(OUTPUT_DIR, "test_predictions.csv"))

    # Qualitative examples: baseline wrong and proposed correct
    qual_rows = []
    for _, row in test_df_out.iterrows():
        if (row['pred_event_base'] != row['pred_event_prop']) and (row['pred_event_prop'] == row['Label']):
            qual_rows.append(row[['News','Label','pred_event_base','pred_event_prop','Sentiment','pred_sent_base','pred_sent_prop']].to_dict())
        if len(qual_rows) >= 10:
            break
    qual_df = pd.DataFrame(qual_rows)
    qual_df.to_csv(os.path.join(OUTPUT_DIR, "qual_examples.csv"), index=False)
    print("Saved qualitative examples to:", os.path.join(OUTPUT_DIR, "qual_examples.csv"))

    # Save classification reports & confusion matrices
    print_and_save_report(y_test_event, ypred_event_base, le_event, "event_baseline")
    print_and_save_report(y_test_event, ypred_event_prop, le_event, "event_proposed")
    print_and_save_report(y_test_sent, ypred_sent_base, le_sent, "sent_baseline")
    print_and_save_report(y_test_sent, ypred_sent_prop, le_sent, "sent_proposed")

    # Plot confusion matrix for proposed event classification
    plot_confusion_matrix(y_test_event, ypred_event_prop, le_event.classes_, "Event Classification (Proposed)", "cm_events_proposed.png")
    plot_confusion_matrix(y_test_event, ypred_event_base, le_event.classes_, "Event Classification (Baseline)", "cm_events_baseline.png")
    plot_confusion_matrix(y_test_sent, ypred_sent_prop, le_sent.classes_, "Sentiment Classification (Proposed)", "cm_sent_proposed.png")
    plot_confusion_matrix(y_test_sent, ypred_sent_base, le_sent.classes_, "Sentiment Classification (Baseline)", "cm_sent_baseline.png")

    # -------------------------
    # Optional: BiLSTM-Attention baseline (if TF available)
    # -------------------------
    if TF_AVAILABLE:
        print("\nTraining BiLSTM baseline (Keras) — this may be slow without GPU.")
        # Tokenizer on combined training data
        tokenizer = Tokenizer(num_words=20000, oov_token="<OOV>")
        tokenizer.fit_on_texts(train_df['News_clean'])
        X_tr_seq = tokenizer.texts_to_sequences(train_df['News_clean'])
        X_te_seq = tokenizer.texts_to_sequences(test_df['News_clean'])
        X_tr_pad = pad_sequences(X_tr_seq, maxlen=SEQUENCE_MAX_LEN, padding='post', truncating='post')
        X_te_pad = pad_sequences(X_te_seq, maxlen=SEQUENCE_MAX_LEN, padding='post', truncating='post')


        # Build multi-class classifier (events)
        n_classes_event = len(le_event.classes_)
        inp = Input(shape=(SEQUENCE_MAX_LEN,))
        emb = Embedding(input_dim=min(len(tokenizer.word_index)+1, 20000), output_dim=EMBEDDING_DIM, input_length=SEQUENCE_MAX_LEN)(inp)
        x = Bidirectional(LSTM(64, return_sequences=True))(emb)
        x_avg = GlobalAveragePooling1D()(x)
        x_max = GlobalMaxPool1D()(x)
        x = Concatenate()([x_avg, x_max])
        x = Dropout(0.3)(x)
        out = Dense(n_classes_event, activation='softmax')(x)
        model = Model(inputs=inp, outputs=out)
        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
        model.summary()

        model.fit(X_tr_pad, y_train_event, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)
        ypred_event_bilstm_proba = model.predict(X_te_pad)
        ypred_event_bilstm = np.argmax(ypred_event_bilstm_proba, axis=1)

        bilstm_metrics = compute_metrics(y_test_event, ypred_event_bilstm)
        print("BiLSTM event metrics:", bilstm_metrics)
        # Save model predictions and report
        test_df_out['pred_event_bilstm'] = le_event.inverse_transform(ypred_event_bilstm)
        test_df_out.to_csv(os.path.join(OUTPUT_DIR, "test_predictions_with_bilstm.csv"), index=False)
        with open(os.path.join(OUTPUT_DIR, "bilstm_event_metrics.json"), 'w') as f:
            json.dump(bilstm_metrics, f, indent=2)

    print("\nExperiment run complete. Results saved in folder:", OUTPUT_DIR)
    print("Key files: experiment_results_summary.csv, test_predictions.csv, qual_examples.csv")

if __name__ == "__main__":
    main()





pip install pandas numpy scikit-learn scipy transformers datasets tokenizers torch sentence-transformers faiss-cpu

"""
run_agentic_experiments.py

Context-Engineered Agentic AI experiments for:
Event extraction & Sentiment classification on Indian banking news.

Features:
- Training-set-only balancing (oversampling)
- Dynamic trigger generation (cleaned, top-k per class)
- TF-IDF + keyword flags baseline (Logistic Regression)
- Transformer-based classifier (BERT) with simple Agentic context injection (retrieved context)
- Metrics: accuracy, micro/macro precision/recall/F1
- Saves results to experiment_outputs/
"""

import os
import re
import json
import random
import argparse
from collections import defaultdict
from datetime import datetime

import numpy as np
import pandas as pd
from scipy.sparse import hstack, csr_matrix

from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.utils import resample
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix

# optional: transformer libs
try:
    import torch
    from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
    from datasets import Dataset, ClassLabel, load_metric
    TRANSFORMERS_AVAILABLE = True
except Exception as e:
    TRANSFORMERS_AVAILABLE = False
    print("Transformers not available. Install 'transformers', 'datasets', and 'torch' to run transformer experiments.")

# Optional retrieval using sentence-transformers if available
try:
    from sentence_transformers import SentenceTransformer
    from sklearn.metrics.pairwise import cosine_similarity
    S2V_AVAILABLE = True
except Exception:
    S2V_AVAILABLE = False

# ------------------------
# Configuration
# ------------------------
SEED = 42
random.seed(SEED)
np.random.seed(SEED)
os.environ['PYTHONHASHSEED'] = str(SEED)

INPUT_XLSX = "News_event_sentiment_labeled.xlsx"  # update as needed
OUTPUT_DIR = "experiment_outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

SPLIT_MODE = "stratified"  # 'temporal' or 'stratified'
TEST_SIZE = 0.30
TFIDF_MAX_FEATURES = 3000
TOP_K_TRIGGERS = 10          # top-k keywords per event class
BALANCE_TRAIN = True         # oversample train only
DO_TRAIN_TRANSFORMER = True  # requires transformers & torch
TRANSFORMER_MODEL = "bert-base-uncased"
BATCH_SIZE = 8
EPOCHS = 30
MAX_SEQ_LEN = 256

# ------------------------
# Helpers
# ------------------------
def clean_text(s):
    s = "" if pd.isna(s) else str(s)
    s = s.lower()
    s = re.sub(r'\s+', ' ', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    return s.strip()

def compute_metrics_dict(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)
    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)
    return {
        'accuracy': acc,
        'micro_precision': prec_micro, 'micro_recall': rec_micro, 'micro_f1': f1_micro,
        'macro_precision': prec_macro, 'macro_recall': rec_macro, 'macro_f1': f1_macro
    }

def balance_training_set(train_df, label_col='Label'):
    # Oversample minority classes in train only
    counts = train_df[label_col].value_counts()
    max_count = counts.max()
    dfs = []
    for lbl, grp in train_df.groupby(label_col):
        if len(grp) < max_count:
            grp_up = resample(grp, replace=True, n_samples=max_count, random_state=SEED)
            dfs.append(grp_up)
        else:
            dfs.append(grp)
    df_bal = pd.concat(dfs).sample(frac=1, random_state=SEED).reset_index(drop=True)
    return df_bal

def generate_event_triggers(df, label_col='Label', text_col='News', top_k=TOP_K_TRIGGERS):
    """
    Generate top-k frequent cleaned tokens per label using CountVectorizer.
    Filter tokens <3 chars and English stopwords implicitly via vectorizer.
    """
    vectorizer = CountVectorizer(max_features=5000, stop_words='english', min_df=2)
    # Fit on entire corpus to build vocab
    X = vectorizer.fit_transform(df[text_col].apply(clean_text))
    vocab = np.array(vectorizer.get_feature_names_out())
    triggers = {}
    for label in sorted(df[label_col].unique()):
        subset = df[df[label_col] == label]
        if subset.shape[0] == 0:
            triggers[label] = []
            continue
        X_sub = vectorizer.transform(subset[text_col].apply(clean_text))
        freqs = np.array(X_sub.sum(axis=0)).flatten()
        if freqs.sum() == 0:
            triggers[label] = []
            continue
        top_idx = freqs.argsort()[-top_k:][::-1]
        tokens = [tok for tok in vocab[top_idx] if len(tok) > 2]
        triggers[label] = tokens
    return triggers

def keyword_flags_from_triggers(series, triggers):
    # series: iterable of raw text
    rows = []
    labels = list(triggers.keys())
    for txt in series:
        t = clean_text(txt)
        row = []
        for k in labels:
            kwlist = triggers.get(k, [])
            found = 0
            for kw in kwlist:
                if kw in t:
                    found = 1
                    break
            row.append(found)
        rows.append(row)
    return np.array(rows, dtype=int), labels

# Simple retrieval component (Agentic helper)
def build_tfidf_retriever(corpus_texts, max_features=2000):
    # returns vectorizer, matrix
    vec = TfidfVectorizer(max_features=max_features, ngram_range=(1,2), stop_words='english')
    mat = vec.fit_transform([clean_text(s) for s in corpus_texts])
    return vec, mat

def retrieve_top_k(vec, mat, query, k=3):
    qv = vec.transform([clean_text(query)])
    sims = (mat @ qv.T).toarray().flatten()
    idx = np.argsort(sims)[-k:][::-1]
    return idx, sims[idx]

# ------------------------
# Main
# ------------------------
def main():
    assert os.path.exists(INPUT_XLSX), f"Input file not found: {INPUT_XLSX}"
    df = pd.read_excel(INPUT_XLSX)
    print("Loaded", df.shape, "columns:", df.columns.tolist())

    # Basic checks
    assert {'News','Label','Sentiment'}.issubset(set(df.columns)), "Input must contain columns: News, Label, Sentiment"

    # Clean text and parse date if present
    df['News_clean'] = df['News'].apply(clean_text)
    if 'Date' in df.columns:
        df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce')
        df.loc[df['Date_parsed'].isna(), 'Date_parsed'] = pd.date_range('2017-01-01', periods=df['Date_parsed'].isna().sum())
    else:
        df['Date_parsed'] = pd.date_range('2017-01-01', periods=len(df), freq='D')

    # Label encoders (fit on whole dataset so inverse-transform works)
    le_event = LabelEncoder().fit(df['Label'].astype(str))
    le_sent = LabelEncoder().fit(df['Sentiment'].astype(str))

    # Splitting
    if SPLIT_MODE == 'temporal':
        df = df.sort_values('Date_parsed').reset_index(drop=True)
        n = len(df)
        train_end = int(0.7 * n)
        val_end = train_end + int(0.15 * n)
        train_df = df.iloc[:train_end].reset_index(drop=True)
        val_df = df.iloc[train_end:val_end].reset_index(drop=True)
        test_df = df.iloc[val_end:].reset_index(drop=True)
    else:
        train_df, temp_df = train_test_split(df, test_size=TEST_SIZE, random_state=SEED, stratify=df['Label'])
        val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['Label'])

    print("Split sizes -> train:", len(train_df), "val:", len(val_df), "test:", len(test_df))
    # Optionally balance only training set
    if BALANCE_TRAIN:
        train_df = balance_training_set(train_df, label_col='Label')
        print("Balanced train size per class:", train_df['Label'].value_counts().to_dict())

    # ------------------------
    # Generate dynamic triggers from training set
    # ------------------------
    triggers = generate_event_triggers(train_df, label_col='Label', text_col='News', top_k=TOP_K_TRIGGERS)
    with open(os.path.join(OUTPUT_DIR, "dynamic_triggers.json"), "w") as f:
        json.dump(triggers, f, indent=2)
    print("Saved dynamic triggers to experiment_outputs/dynamic_triggers.json")
    # Optionally print triggers
    for k,v in triggers.items():
        print(f"{k}: {v[:10]}")

    # ------------------------
    # Baseline & Proposed (LogisticRegression) using TF-IDF + flags
    # ------------------------
    tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=(1,2), stop_words='english')
    X_train_tfidf = tfidf.fit_transform(train_df['News_clean'])
    X_val_tfidf = tfidf.transform(val_df['News_clean'])
    X_test_tfidf = tfidf.transform(test_df['News_clean'])

    # flags
    X_train_flags, flag_labels = keyword_flags_from_triggers(train_df['News'], triggers)
    X_val_flags, _ = keyword_flags_from_triggers(val_df['News'], triggers)
    X_test_flags, _ = keyword_flags_from_triggers(test_df['News'], triggers)

    X_train_prop = hstack([X_train_tfidf, csr_matrix(X_train_flags)])
    X_val_prop = hstack([X_val_tfidf, csr_matrix(X_val_flags)])
    X_test_prop = hstack([X_test_tfidf, csr_matrix(X_test_flags)])

    y_train_event = le_event.transform(train_df['Label'].astype(str))
    y_val_event = le_event.transform(val_df['Label'].astype(str))
    y_test_event = le_event.transform(test_df['Label'].astype(str))

    y_train_sent = le_sent.transform(train_df['Sentiment'].astype(str))
    y_val_sent = le_sent.transform(val_df['Sentiment'].astype(str))
    y_test_sent = le_sent.transform(test_df['Sentiment'].astype(str))

    # Baseline TF-IDF + Logistic Regression
    baseline_clf = LogisticRegression(max_iter=500, solver='liblinear', class_weight='balanced', random_state=SEED)
    baseline_clf.fit(X_train_tfidf, y_train_event)
    ypred_event_base = baseline_clf.predict(X_test_tfidf)

    # Proposed TF-IDF+flags + Logistic Regression
    proposed_clf = LogisticRegression(max_iter=500, solver='liblinear', class_weight='balanced', random_state=SEED)
    proposed_clf.fit(X_train_prop, y_train_event)
    ypred_event_prop = proposed_clf.predict(X_test_prop)

    ev_base_metrics = compute_metrics_dict(y_test_event, ypred_event_base)
    ev_prop_metrics = compute_metrics_dict(y_test_event, ypred_event_prop)
    print("Event baseline metrics:", ev_base_metrics)
    print("Event proposed metrics:", ev_prop_metrics)

    # Save summary
    results_summary = {
        'event_baseline': ev_base_metrics,
        'event_proposed': ev_prop_metrics
    }
    pd.DataFrame(results_summary).T.to_csv(os.path.join(OUTPUT_DIR, "tfidf_lr_event_results.csv"))

    # Save predictions for qualitative table
    test_out = test_df.copy()
    test_out['pred_event_base'] = le_event.inverse_transform(ypred_event_base)
    test_out['pred_event_prop'] = le_event.inverse_transform(ypred_event_prop)
    test_out.to_csv(os.path.join(OUTPUT_DIR, "test_predictions_tfidf_lr.csv"), index=False)
    print("Saved TF-IDF LR predictions to experiment_outputs/test_predictions_tfidf_lr.csv")

    # Detailed classification reports
    with open(os.path.join(OUTPUT_DIR, "tfidf_lr_event_report_base.txt"), "w") as f:
        f.write(classification_report(y_test_event, ypred_event_base, target_names=le_event.classes_, zero_division=0))
    with open(os.path.join(OUTPUT_DIR, "tfidf_lr_event_report_prop.txt"), "w") as f:
        f.write(classification_report(y_test_event, ypred_event_prop, target_names=le_event.classes_, zero_division=0))

    # ------------------------
    # Simple Agentic Retrieval setup (local retrieval using TF-IDF similarity)
    # ------------------------
    # Build retriever on whole corpus (or training set) - we'll use TF-IDF matrix for retrieval
    retriever_vec, retriever_mat = build_tfidf_retriever(df['News_clean'].tolist(), max_features=TFIDF_MAX_FEATURES)
    # For each test document, retrieve top-k similar docs (from train set ideally)
    K_RETRIEVE = 3

    # ------------------------
    # Transformer-based model (fine-tune) with context-window injection
    # ------------------------
    if DO_TRAIN_TRANSFORMER and TRANSFORMERS_AVAILABLE:
        print("Preparing transformer dataset with agentic context injection...")
        tokenizer = AutoTokenizer.from_pretrained(TRANSFORMER_MODEL)

        def assemble_context_text(row, k=K_RETRIEVE):
            # retrieve top-k similar (from retriever_mat) and concat with the news text
            idxs, sims = retrieve_top_k(retriever_vec, retriever_mat, row['News'], k=k)
            # Exclude the same article if it matches; pick ones from training set if possible
            context_texts = []
            for i in idxs:
                # basic guard
                context_texts.append(df.iloc[i]['News_clean'])
            # Compose input: [CONTEXT] + [SEP] + [ARTICLE]
            context_block = " ".join(context_texts)
            return (context_block + " </s> " + row['News_clean'])[:2000]  # truncate to safe length

        # Create HuggingFace dataset for training (events)
        train_rows = []
        for _, r in train_df.iterrows():
            ctxt = assemble_context_text(r, k=K_RETRIEVE)
            train_rows.append({"text": ctxt, "label": int(le_event.transform([r['Label']])[0])})
        val_rows = []
        for _, r in val_df.iterrows():
            ctxt = assemble_context_text(r, k=K_RETRIEVE)
            val_rows.append({"text": ctxt, "label": int(le_event.transform([r['Label']])[0])})
        test_rows = []
        for _, r in test_df.iterrows():
            ctxt = assemble_context_text(r, k=K_RETRIEVE)
            test_rows.append({"text": ctxt, "label": int(le_event.transform([r['Label']])[0])})

        ds_train = Dataset.from_pandas(pd.DataFrame(train_rows)).remove_columns(["__index_level_0__"]) if 'pandas' in str(type(pd.DataFrame())) else Dataset.from_dict(train_rows)
        ds_val = Dataset.from_pandas(pd.DataFrame(val_rows)).remove_columns(["__index_level_0__"])
        ds_test = Dataset.from_pandas(pd.DataFrame(test_rows)).remove_columns(["__index_level_0__"])

        # tokenization
        def tokenize_fn(examples):
            return tokenizer(examples["text"], truncation=True, padding="max_length", max_length=MAX_SEQ_LEN)
        ds_train = ds_train.map(tokenize_fn, batched=True)
        ds_val = ds_val.map(tokenize_fn, batched=True)
        ds_test = ds_test.map(tokenize_fn, batched=True)

        ds_train = ds_train.rename_column("label", "labels")
        ds_val = ds_val.rename_column("label", "labels")
        ds_test = ds_test.rename_column("label", "labels")

        ds_train.set_format(type='torch', columns=['input_ids','attention_mask','labels'])
        ds_val.set_format(type='torch', columns=['input_ids','attention_mask','labels'])
        ds_test.set_format(type='torch', columns=['input_ids','attention_mask','labels'])

        model = AutoModelForSequenceClassification.from_pretrained(TRANSFORMER_MODEL, num_labels=len(le_event.classes_))
        training_args = TrainingArguments(
            output_dir=os.path.join(OUTPUT_DIR,"transformer_event"),
            num_train_epochs=EPOCHS,
            per_device_train_batch_size=BATCH_SIZE,
            per_device_eval_batch_size=BATCH_SIZE,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            logging_steps=10,
            seed=SEED,
            load_best_model_at_end=True,
            metric_for_best_model="eval_loss"
        )

        metric = load_metric("accuracy")  # for quick logging; we compute detailed metrics separately

        def compute_metrics_trainer(eval_pred):
            logits, labels = eval_pred
            preds = np.argmax(logits, axis=-1)
            return metric.compute(predictions=preds, references=labels)

        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=ds_train,
            eval_dataset=ds_val,
            compute_metrics=compute_metrics_trainer
        )

        print("Starting transformer fine-tuning (this may take time)...")
        trainer.train()
        # evaluate on test
        preds_output = trainer.predict(ds_test)
        preds = np.argmax(preds_output.predictions, axis=-1)
        # map to original labels
        y_test_event_transformer = [int(x['label']) for x in test_rows]  # labels used above
        # compute metrics
        t_metrics = compute_metrics_dict(y_test_event_transformer, preds)
        print("Transformer (with context) metrics on test:", t_metrics)
        # Save
        pd.DataFrame({"transformer_event": t_metrics}).T.to_csv(os.path.join(OUTPUT_DIR, "transformer_event_results.csv"))

        # Save test predictions with text
        test_texts = [r['text'] for r in test_rows]
        test_pred_labels = [le_event.inverse_transform([p])[0] for p in preds]
        df_test_preds = pd.DataFrame({
            "text_with_context": test_texts,
            "pred_event_transformer": test_pred_labels,
            "true_event": [le_event.inverse_transform([int(x['label'])])[0] for x in test_rows]
        })
        df_test_preds.to_csv(os.path.join(OUTPUT_DIR, "test_predictions_transformer.csv"), index=False)
    else:
        print("Skipping transformer training because TRANSFORMERS_AVAILABLE =", TRANSFORMERS_AVAILABLE)

    # ------------------------
    # Qualitative examples (cases where proposed changed prediction to correct one)
    # ------------------------
    qual_rows = []
    for _, row in test_out.iterrows():
        if (row['pred_event_base'] != row['pred_event_prop']) and (row['pred_event_prop'] == row['Label']):
            qual_rows.append({
                "News": row['News'],
                "TrueEvent": row['Label'],
                "BaselinePred": row['pred_event_base'],
                "ProposedPred": row['pred_event_prop']
            })
        if len(qual_rows) >= 10:
            break
    pd.DataFrame(qual_rows).to_csv(os.path.join(OUTPUT_DIR, "qual_examples_tfidf_lr.csv"), index=False)

    print("Experiment outputs saved in", OUTPUT_DIR)
    print("Key files: dynamic_triggers.json, tfidf_lr_event_results.csv, test_predictions_tfidf_lr.csv, qual_examples_tfidf_lr.csv")
    if DO_TRAIN_TRANSFORMER and TRANSFORMERS_AVAILABLE:
        print("Transformer outputs: transformer_event_results.csv, test_predictions_transformer.csv")

if __name__ == "__main__":
    main()

from google.colab import files
files.download('experiment_outputs/experiment_results_summary.csv')
files.download('experiment_outputs/test_predictions_tfidf_lr.csv')
files.download('experiment_outputs/qual_examples_tfidf_lr.csv')
files.download('experiment_outputs/tfidf_lr_event_report_base.txt')
files.download('experiment_outputs/tfidf_lr_event_report_prop.txt')

"""#Complete code"""

!pip install scikit-learn pandas matplotlib seaborn tensorflow transformers -q

"""
Colab Experiment Script
Context-Engineered Agentic AI for Event & Sentiment Classification
Author: Your Name
"""

# ===============================
# Setup
# ===============================
!pip install scikit-learn pandas matplotlib seaborn tensorflow transformers -q

import os, re, random, json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, confusion_matrix
from scipy.sparse import hstack, csr_matrix

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Layer
import tensorflow.keras.backend as K

# ===============================
# File Upload
# ===============================
from google.colab import files
# Check if the file already exists from previous uploads to avoid re-uploading
file_name = "News_event_sentiment_labeled (5).xlsx" # Assuming this was the last uploaded file name from the previous cell output
if not os.path.exists(file_name):
    uploaded = files.upload()  # upload your News_event_sentiment_labeled.xlsx
    FILENAME = list(uploaded.keys())[0]
    print("Uploaded:", FILENAME)
else:
    FILENAME = file_name
    print(f"Using existing file: {FILENAME}")


# ===============================
# Helpers
# ===============================
SEED = 42
random.seed(SEED)
np.random.seed(SEED)

def clean_text(s):
    s = "" if pd.isna(s) else str(s)
    s = s.lower()
    s = re.sub(r'\s+', ' ', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    return s.strip()

def compute_metrics_dict(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)
    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)
    return {
        'accuracy': acc,
        'micro_precision': prec_micro, 'micro_recall': rec_micro, 'micro_f1': f1_micro,
        'macro_precision': prec_macro, 'macro_recall': rec_macro, 'macro_f1': f1_macro
    }

def plot_confusion(y_true, y_pred, labels, title):
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(7,6))
    sns.heatmap(cm, annot=True, fmt="d", xticklabels=labels, yticklabels=labels, cmap="Blues")
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title(title)
    plt.show()

# Lexicon (small demo version – replace with full LM lexicon if available)
LM_POS = {"upgrade","stable","growth","profit","beat","improve","positive"}
LM_NEG = {"downgrade","loss","fraud","slump","decline","cut","negative"}
def lexicon_score(text):
    toks = clean_text(text).split()
    pos = sum(1 for t in toks if t in LM_POS)
    neg = sum(1 for t in toks if t in LM_NEG)
    return (pos - neg) / (len(toks)+1e-9)

# Simple event rule flags
def build_rule_flags(series):
    flags = []
    for t in series:
        s = clean_text(t)
        flags.append([
            int("repo" in s or "rate hike" in s),
            int("downgrade" in s or "rating" in s),
            int("fraud" in s or "scam" in s or "npa" in s),
            int("merger" in s or "acquir" in s),
            int("quarter" in s or "earnings" in s)
        ])
    return np.array(flags, dtype=int)

# ===============================
# Load & Preprocess
# ===============================
df = pd.read_excel(FILENAME)
print("Data shape:", df.shape, "Columns:", df.columns.tolist())
df = df.dropna(subset=["News","Label","Sentiment"])
df['News_clean'] = df['News'].apply(clean_text)

# train/val/test split
train_df, temp_df = train_test_split(df, test_size=0.3, random_state=SEED, stratify=df['Label'])
val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['Label'])

# encode
le_event = LabelEncoder().fit(df['Label'])
le_sent  = LabelEncoder().fit(df['Sentiment'])

y_train_event = le_event.transform(train_df['Label'])
y_test_event  = le_event.transform(test_df['Label'])
y_train_sent  = le_sent.transform(train_df['Sentiment'])
y_test_sent   = le_sent.transform(test_df['Sentiment'])

# TF-IDF
tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words="english")
X_train_tfidf = tfidf.fit_transform(train_df['News_clean'])
X_test_tfidf  = tfidf.transform(test_df['News_clean'])

# Lexicon score
train_df['lex_score'] = train_df['News'].apply(lexicon_score)
test_df['lex_score']  = test_df['News'].apply(lexicon_score)
scaler = StandardScaler()
X_train_lex = scaler.fit_transform(train_df[['lex_score']])
X_test_lex  = scaler.transform(test_df[['lex_score']])

# Rule flags
train_rules = csr_matrix(build_rule_flags(train_df['News']))
test_rules  = csr_matrix(build_rule_flags(test_df['News']))

# Proposed feature set
X_train_prop = hstack([X_train_tfidf, train_rules, csr_matrix(X_train_lex)])
X_test_prop  = hstack([X_test_tfidf, test_rules, csr_matrix(X_test_lex)])

# ===============================
# 1. Lexicon baseline
# ===============================
print("\n=== Lexicon Baseline (Sentiment only) ===")
lex_pred = np.array([1 if lexicon_score(t)>0 else (0 if lexicon_score(t)<0 else 2) for t in test_df['News']])
metrics_lex = compute_metrics_dict(y_test_sent, lex_pred)
print(metrics_lex)

# ===============================
# 2. Naive Bayes baseline
# ===============================
print("\n=== Naive Bayes (TF-IDF) ===")
nb = MultinomialNB()
nb.fit(X_train_tfidf, y_train_event)
ypred_nb = nb.predict(X_test_tfidf)
metrics_nb = compute_metrics_dict(y_test_event, ypred_nb)
print(metrics_nb)

# ===============================
# 3. SVM baseline
# ===============================
print("\n=== SVM (TF-IDF) ===")
svc = LinearSVC(class_weight='balanced', max_iter=2000, random_state=SEED)
clf_svc = CalibratedClassifierCV(svc)
clf_svc.fit(X_train_tfidf, y_train_event)
ypred_svc = clf_svc.predict(X_test_tfidf)
metrics_svc = compute_metrics_dict(y_test_event, ypred_svc)
print(metrics_svc)

# ===============================
# 4. Hybrid Rule-based
# ===============================
print("\n=== Hybrid Rule-based (TF-IDF + Rules + Lexicon) ===")
hybrid_clf = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear')
hybrid_clf.fit(X_train_prop, y_train_event)
ypred_hybrid = hybrid_clf.predict(X_test_prop)
metrics_hybrid = compute_metrics_dict(y_test_event, ypred_hybrid)
print(metrics_hybrid)

# ===============================
# 5. Proposed Model (Context-Engineered)
# ===============================
print("\n=== Proposed Model (Context-Engineered AI Features) ===")
prop_clf = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear')
prop_clf.fit(X_train_prop, y_train_event)
ypred_prop = prop_clf.predict(X_test_prop)
metrics_prop = compute_metrics_dict(y_test_event, ypred_prop)
print(metrics_prop)

# ===============================
# 6. Attention-Based Deep (BiLSTM+Attention)
# ===============================
print("\n=== BiLSTM + Attention (Event Classification) ===")

MAX_SEQ_LEN = 200
tokenizer = Tokenizer(num_words=20000, oov_token="<OOV>")
tokenizer.fit_on_texts(train_df['News_clean'])
Xtr_seq = tokenizer.texts_to_sequences(train_df['News_clean'])
Xte_seq = tokenizer.texts_to_sequences(test_df['News_clean'])
Xtr_pad = pad_sequences(Xtr_seq, maxlen=MAX_SEQ_LEN)
Xte_pad = pad_sequences(Xte_seq, maxlen=MAX_SEQ_LEN)
n_classes = len(le_event.classes_)

class AttentionLayer(Layer):
    def __init__(self, **kwargs):
        super(AttentionLayer, self).__init__(**kwargs)

    def build(self, input_shape):
        # input_shape is (None, MAX_SEQ_LEN, lstm_units * 2) for BiLSTM
        self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], 1), initializer="random_normal", trainable=True)
        super().build(input_shape)

    def call(self, inputs):
        # inputs shape: (None, MAX_SEQ_LEN, lstm_units * 2)
        # self.W shape: (lstm_units * 2, 1)
        # e shape: (None, MAX_SEQ_LEN, 1)
        e = K.tanh(K.dot(inputs, self.W))
        # attention_weights shape: (None, MAX_SEQ_LEN, 1)
        attention_weights = K.softmax(e, axis=1)
        # weighted_input shape: (None, MAX_SEQ_LEN, lstm_units * 2)
        weighted_input = inputs * attention_weights
        # context_vector shape: (None, lstm_units * 2)
        context_vector = K.sum(weighted_input, axis=1)
        return context_vector

    def compute_output_shape(self, input_shape):
        # Output shape is (None, lstm_units * 2)
        return (input_shape[0], input_shape[-1])


inp = Input(shape=(MAX_SEQ_LEN,))
emb = Embedding(len(tokenizer.word_index)+1, 100, input_length=MAX_SEQ_LEN)(inp)
x = Bidirectional(LSTM(64, return_sequences=True))(emb)
x = AttentionLayer()(x) # This layer now outputs (None, 128)
x = Dropout(0.3)(x)
out = Dense(n_classes, activation="softmax")(x)
model = Model(inp, out)
model.compile(optimizer="adam", loss="sparse_categorical_crossentropy", metrics=["accuracy"])
model.summary() # Display model summary after fixing the layer

model.fit(Xtr_pad, y_train_event, epochs=30, batch_size=32, validation_split=0.1, verbose=1)
ypred_bilstm = model.predict(Xte_pad).argmax(axis=1)
metrics_bilstm = compute_metrics_dict(y_test_event, ypred_bilstm)
print(metrics_bilstm)

# ===============================
# Save & Compare Results
# ===============================
results = {
    "Lexicon_Sentiment": metrics_lex,
    "NaiveBayes_Event": metrics_nb,
    "SVM_Event": metrics_svc,
    "Hybrid_Event": metrics_hybrid,
    "Proposed_Event": metrics_prop,
    "BiLSTM_Attention_Event": metrics_bilstm
}
pd.DataFrame(results).T.round(3)

"""#Proposed changed"""

"""
Colab Experiment Script
Context-Engineered Agentic AI for Event & Sentiment Classification
Author: Your Name
"""

# ===============================
# Setup
# ===============================
!pip install scikit-learn pandas matplotlib seaborn tensorflow transformers -q

import os, re, random, json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix
from scipy.sparse import hstack, csr_matrix

import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Dropout, Layer
import tensorflow.keras.backend as K

from transformers import AutoTokenizer, TFAutoModel

# ===============================
# File Upload
# ===============================
from google.colab import files
uploaded = files.upload()  # Upload your News_event_sentiment_labeled.xlsx
FILENAME = list(uploaded.keys())[0]

# ===============================
# Helpers
# ===============================
SEED = 42
random.seed(SEED)
np.random.seed(SEED)

def clean_text(s):
    s = "" if pd.isna(s) else str(s)
    s = s.lower()
    s = re.sub(r'\s+', ' ', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    return s.strip()

def compute_metrics_dict(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec_micro, rec_micro, f1_micro, _ = precision_recall_fscore_support(y_true, y_pred, average='micro', zero_division=0)
    prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(y_true, y_pred, average='macro', zero_division=0)
    return {
        'accuracy': acc,
        'micro_precision': prec_micro, 'micro_recall': rec_micro, 'micro_f1': f1_micro,
        'macro_precision': prec_macro, 'macro_recall': rec_macro, 'macro_f1': f1_macro
    }

# Lexicon (demo version – replace with full LM lexicon if available)
LM_POS = {"upgrade","stable","growth","profit","beat","improve","positive"}
LM_NEG = {"downgrade","loss","fraud","slump","decline","cut","negative"}
def lexicon_score(text):
    toks = clean_text(text).split()
    pos = sum(1 for t in toks if t in LM_POS)
    neg = sum(1 for t in toks if t in LM_NEG)
    return (pos - neg) / (len(toks)+1e-9)

# Simple event rule flags
def build_rule_flags(series):
    flags = []
    for t in series:
        s = clean_text(t)
        flags.append([
            int("repo" in s or "rate hike" in s),
            int("downgrade" in s or "rating" in s),
            int("fraud" in s or "scam" in s or "npa" in s),
            int("merger" in s or "acquir" in s),
            int("quarter" in s or "earnings" in s)
        ])
    return np.array(flags, dtype=int)

# ===============================
# Load & Preprocess
# ===============================
df = pd.read_excel(FILENAME)
df = df.dropna(subset=["News","Label","Sentiment"])
df['News_clean'] = df['News'].apply(clean_text)

# Split
train_df, temp_df = train_test_split(df, test_size=0.3, random_state=SEED, stratify=df['Label'])
val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['Label'])

# Encode
le_event = LabelEncoder().fit(df['Label'])
le_sent  = LabelEncoder().fit(df['Sentiment'])
y_train_event = le_event.transform(train_df['Label'])
y_test_event  = le_event.transform(test_df['Label'])
y_train_sent  = le_sent.transform(train_df['Sentiment'])
y_test_sent   = le_sent.transform(test_df['Sentiment'])

# TF-IDF
tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words="english")
X_train_tfidf = tfidf.fit_transform(train_df['News_clean'])
X_test_tfidf  = tfidf.transform(test_df['News_clean'])

# Lexicon + Rule features
train_df['lex_score'] = train_df['News'].apply(lexicon_score)
test_df['lex_score']  = test_df['News'].apply(lexicon_score)
scaler = StandardScaler()
X_train_lex = scaler.fit_transform(train_df[['lex_score']])
X_test_lex  = scaler.transform(test_df[['lex_score']])
train_rules = csr_matrix(build_rule_flags(train_df['News']))
test_rules  = csr_matrix(build_rule_flags(test_df['News']))
X_train_prop = hstack([X_train_tfidf, train_rules, csr_matrix(X_train_lex)])
X_test_prop  = hstack([X_test_tfidf, test_rules, csr_matrix(X_test_lex)])

# ===============================
# Baseline Models
# ===============================
print("\n=== Lexicon Baseline (Sentiment only) ===")
lex_pred = np.array([1 if lexicon_score(t)>0 else (0 if lexicon_score(t)<0 else 2) for t in test_df['News']])
metrics_lex = compute_metrics_dict(y_test_sent, lex_pred)

print("\n=== Naive Bayes (TF-IDF) ===")
nb = MultinomialNB()
nb.fit(X_train_tfidf, y_train_event)
ypred_nb = nb.predict(X_test_tfidf)
metrics_nb = compute_metrics_dict(y_test_event, ypred_nb)

print("\n=== SVM (TF-IDF) ===")
svc = LinearSVC(class_weight='balanced', max_iter=2000, random_state=SEED)
clf_svc = CalibratedClassifierCV(svc)
clf_svc.fit(X_train_tfidf, y_train_event)
ypred_svc = clf_svc.predict(X_test_tfidf)
metrics_svc = compute_metrics_dict(y_test_event, ypred_svc)

print("\n=== Hybrid Rule-based (TF-IDF + Rules + Lexicon) ===")
hybrid_clf = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear')
hybrid_clf.fit(X_train_prop, y_train_event)
ypred_hybrid = hybrid_clf.predict(X_test_prop)
metrics_hybrid = compute_metrics_dict(y_test_event, ypred_hybrid)

# ===============================
# Transformer: FinBERT Baseline
# ===============================
print("\n=== FinBERT Baseline ===")
finbert_model = "ProsusAI/finbert"
tokenizer_fb = AutoTokenizer.from_pretrained(finbert_model)
model_fb = TFAutoModel.from_pretrained(finbert_model)

def encode_texts(texts, tokenizer, max_len=128):
    enc = tokenizer(texts.tolist(), padding=True, truncation=True, max_length=max_len, return_tensors="tf")
    return model_fb(enc).last_hidden_state[:,0,:].numpy()

X_train_fb = encode_texts(train_df['News_clean'], tokenizer_fb)
X_test_fb  = encode_texts(test_df['News_clean'], tokenizer_fb)

finbert_clf = LogisticRegression(max_iter=1000, class_weight='balanced')
finbert_clf.fit(X_train_fb, y_train_event)
ypred_finbert = finbert_clf.predict(X_test_fb)
metrics_finbert = compute_metrics_dict(y_test_event, ypred_finbert)

# ===============================
# Proposed: Context-Engineered Agentic AI
# Transformer embeddings + rules + lexicon
# ===============================
print("\n=== Proposed: Context-Engineered Agentic AI ===")
X_train_prop_agent = np.hstack([X_train_fb, train_rules.toarray(), X_train_lex])
X_test_prop_agent  = np.hstack([X_test_fb, test_rules.toarray(), X_test_lex])

prop_agent_clf = LogisticRegression(max_iter=1000, class_weight='balanced')
prop_agent_clf.fit(X_train_prop_agent, y_train_event)
ypred_prop_agent = prop_agent_clf.predict(X_test_prop_agent)
metrics_prop_agent = compute_metrics_dict(y_test_event, ypred_prop_agent)

# ===============================
# Results Summary
# ===============================
results = {
    "Lexicon_Sentiment": metrics_lex,
    "NaiveBayes_Event": metrics_nb,
    "SVM_Event": metrics_svc,
    "Hybrid_Event": metrics_hybrid,
    "FinBERT_Baseline": metrics_finbert,
    "Proposed_Agentic_AI": metrics_prop_agent
}
pd.DataFrame(results).T.round(3)

"""Proposed model with Context Engineered Agentic AI"""

!pip install -q transformers tensorflow scikit-learn pandas sentence-transformers openpyxl

# Colab script: Multitask Context-Engineered Agentic AI + baselines
# Save as a single cell and run. Upload your Excel when prompted.
# Requirements: transformers, tensorflow, sklearn, pandas, sentence-transformers (optional)


import os, re, random, json
from collections import Counter
from datetime import datetime
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.utils import resample
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

from scipy.sparse import hstack, csr_matrix

from transformers import AutoTokenizer, TFAutoModel

# Optional sentence-transformers for retrieval (context)
try:
    from sentence_transformers import SentenceTransformer
    S2V_AVAILABLE = True
except Exception:
    S2V_AVAILABLE = False

# Added imports for Keras layers
from tensorflow.keras.layers import LayerNormalization, Concatenate, Layer

# ------------------------
# Config
# ------------------------
SEED = 42
random.seed(SEED); np.random.seed(SEED)
tf.random.set_seed(SEED)

INPUT_FILE = None  # leave None to prompt upload
OUTPUT_DIR = "experiment_outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

SPLIT_MODE = "stratified"   # 'temporal' or 'stratified'
TEST_SIZE = 0.30
BALANCE_TRAIN = True        # oversample training set only
TFIDF_MAX_FEATURES = 5000
TOP_K_TRIGGERS = 10

FINBERT_MODEL = "ProsusAI/finbert"  # FinBERT
MAX_SEQ_LEN = 192
BATCH_SIZE = 8
EPOCHS = 10   # you can increase if GPU available
LEARNING_RATE = 2e-5
USE_RETRIEVAL_CONTEXT = False  # set True if you want to prepend retrieved context (requires sentence-transformers)

# ------------------------
# Utilities
# ------------------------
def clean_text(s):
    s = "" if pd.isna(s) else str(s)
    s = s.lower()
    s = re.sub(r'\s+', ' ', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    return s.strip()

def compute_metrics(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec_micro = precision_score(y_true, y_pred, average='micro', zero_division=0)
    rec_micro = recall_score(y_true, y_pred, average='micro', zero_division=0)
    f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)
    prec_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)
    rec_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)
    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)
    return {
        'accuracy': acc,
        'micro_precision': prec_micro, 'micro_recall': rec_micro, 'micro_f1': f1_micro,
        'macro_precision': prec_macro, 'macro_recall': rec_macro, 'macro_f1': f1_macro
    }

def print_report(y_true, y_pred, label_encoder, title, out_path=None):
    labels = list(label_encoder.classes_)
    report = classification_report(y_true, y_pred, target_names=labels, zero_division=0)
    print("=== Report:", title, "===\n", report)
    if out_path:
        with open(out_path, "w") as f:
            f.write(report)
    return report

def balance_training_set(df, label_col='Label'):
    # oversample minority classes to match max class count
    max_n = df[label_col].value_counts().max()
    parts = []
    for lbl, g in df.groupby(label_col):
        if len(g) < max_n:
            parts.append(resample(g, replace=True, n_samples=max_n, random_state=SEED))
        else:
            parts.append(g)
    df_bal = pd.concat(parts).sample(frac=1, random_state=SEED).reset_index(drop=True)
    return df_bal

# ------------------------
# Upload file (Colab)
# ------------------------
from google.colab import files
if INPUT_FILE and os.path.exists(INPUT_FILE):
    file_path = INPUT_FILE
else:
    print("Upload your dataset Excel (News_event_sentiment_labeled.xlsx)...")
    uploaded = files.upload()
    file_path = list(uploaded.keys())[0]

print("Loading:", file_path)
df = pd.read_excel(file_path)
print("Raw shape:", df.shape, "Columns:", df.columns.tolist())

# Require columns: News, Label, Sentiment, optionally Date
assert {'News','Label','Sentiment'}.issubset(set(df.columns)), "Dataset must contain News, Label, Sentiment columns"

df = df.dropna(subset=['News','Label','Sentiment']).reset_index(drop=True)
df['News_clean'] = df['News'].apply(clean_text)
if 'Date' in df.columns:
    df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce')
    df.loc[df['Date_parsed'].isna(), 'Date_parsed'] = pd.date_range('2017-01-01', periods=df['Date_parsed'].isna().sum())
else:
    df['Date_parsed'] = pd.date_range('2017-01-01', periods=len(df), freq='D')

# ------------------------
# Split (temporal or stratified)
# ------------------------
if SPLIT_MODE == 'temporal':
    df = df.sort_values('Date_parsed').reset_index(drop=True)
    n = len(df)
    train_end = int(0.7 * n)
    val_end = train_end + int(0.15 * n)
    train_df = df.iloc[:train_end].reset_index(drop=True)
    val_df = df.iloc[train_end:val_end].reset_index(drop=True)
    test_df = df.iloc[val_end:].reset_index(drop=True)
else:
    train_df, temp_df = train_test_split(df, test_size=TEST_SIZE, random_state=SEED, stratify=df['Label'])
    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['Label'])

print("Split sizes: train", len(train_df), "val", len(val_df), "test", len(test_df))

# Balance training set only (recommended)
if BALANCE_TRAIN:
    train_df = balance_training_set(train_df, label_col='Label')
    print("After balancing train class counts:\n", train_df['Label'].value_counts())

# ------------------------
# Label encoders
# ------------------------
le_event = LabelEncoder().fit(df['Label'].astype(str))
le_sent = LabelEncoder().fit(df['Sentiment'].astype(str))
n_events = len(le_event.classes_)
n_sents = len(le_sent.classes_)
print("Event classes:", n_events, "Sentiment classes:", n_sents)

y_train_event = le_event.transform(train_df['Label'])
y_val_event = le_event.transform(val_df['Label'])
y_test_event = le_event.transform(test_df['Label'])

y_train_sent = le_sent.transform(train_df['Sentiment'])
y_val_sent = le_sent.transform(val_df['Sentiment'])
y_test_sent = le_sent.transform(test_df['Sentiment'])

# ------------------------
# Build simple lexicon / rule features (context-engineered components)
# ------------------------
# Small demo lexicons; replace with full Loughran-McDonald if available
LM_POS = {"upgrade","stable","growth","profit","beat","improve","positive"}
LM_NEG = {"downgrade","loss","fraud","slump","decline","cut","negative"}
def lexicon_score(text):
    toks = clean_text(text).split()
    pos = sum(1 for t in toks if t in LM_POS)
    neg = sum(1 for t in toks if t in LM_NEG)
    return (pos - neg) / (len(toks) + 1e-9)

def build_rule_flags(series):
    rows=[]
    for t in series:
        s = clean_text(t)
        rows.append([
            int("repo" in s or "rate hike" in s or "rate cut" in s),
            int("downgrade" in s or "rating" in s),
            int("fraud" in s or "scam" in s or "npa" in s),
            int("merger" in s or "acquir" in s),
            int("quarter" in s or "earnings" in s or "q1" in s)
        ])
    return np.array(rows, dtype=int)

train_df['lex_score'] = train_df['News'].apply(lexicon_score)
val_df['lex_score'] = val_df['News'].apply(lexicon_score)
test_df['lex_score'] = test_df['News'].apply(lexicon_score)

train_rules = build_rule_flags(train_df['News'])
val_rules = build_rule_flags(val_df['News'])
test_rules = build_rule_flags(test_df['News'])

# ------------------------
# TF-IDF baseline features
# ------------------------
tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=(1,2), stop_words='english')
X_train_tfidf = tfidf.fit_transform(train_df['News_clean'])
X_val_tfidf = tfidf.transform(val_df['News_clean'])
X_test_tfidf = tfidf.transform(test_df['News_clean'])

# ------------------------
# Baseline: Lexicon (sentiment)
# ------------------------
# Map lexicon to sentiment class indices (choose mapping that matches your Sentiment labels)
# Here we assume le_sent.classes_ contains something like ['negative','neutral','positive']
def lexicon_pred_to_label(score):
    if score > 0:
        lab = "positive"
    elif score < 0:
        lab = "negative"
    else:
        lab = "neutral"
    # fallback if labels differ
    if lab not in le_sent.classes_:
        # choose closest: map to first class index if mismatch
        return 0
    return int(le_sent.transform([lab])[0])

lex_preds = [lexicon_pred_to_label(s) for s in test_df['lex_score']]
lex_metrics = compute_metrics(y_test_sent, lex_preds)
print("Lexicon baseline (sentiment) metrics:", lex_metrics)

# ------------------------
# Baseline: MultinomialNB (TF-IDF)
# ------------------------
nb = MultinomialNB()
nb.fit(X_train_tfidf, y_train_event)
ypred_nb = nb.predict(X_test_tfidf)
nb_metrics = compute_metrics(y_test_event, ypred_nb)
print("NaiveBayes (TF-IDF) event metrics:", nb_metrics)
print_report(y_test_event, ypred_nb, le_event, "NB Event", os.path.join(OUTPUT_DIR,"nb_event_report.txt"))

# ------------------------
# Baseline: SVM (TF-IDF)
# ------------------------
svc = LinearSVC(class_weight='balanced', max_iter=2000, random_state=SEED)
clf_svc = CalibratedClassifierCV(svc)
clf_svc.fit(X_train_tfidf, y_train_event)
ypred_svc = clf_svc.predict(X_test_tfidf)
svc_metrics = compute_metrics(y_test_event, ypred_svc)
print("SVM (TF-IDF) event metrics:", svc_metrics)
print_report(y_test_event, ypred_svc, le_event, "SVM Event", os.path.join(OUTPUT_DIR,"svc_event_report.txt"))

# ------------------------
# Baseline: Hybrid Rule-based (TF-IDF + rules + lex)
# ------------------------
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
Xtr_lex = scaler.fit_transform(train_df[['lex_score']])
Xte_lex = scaler.transform(test_df[['lex_score']])
X_train_hybrid = hstack([X_train_tfidf, csr_matrix(train_rules), csr_matrix(Xtr_lex)])
X_test_hybrid = hstack([X_test_tfidf, csr_matrix(test_rules), csr_matrix(Xte_lex)])

hybrid_clf = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear', random_state=SEED)
hybrid_clf.fit(X_train_hybrid, y_train_event)
ypred_hybrid = hybrid_clf.predict(X_test_hybrid)
hybrid_metrics = compute_metrics(y_test_event, ypred_hybrid)
print("Hybrid (TF-IDF+rules+lex) event metrics:", hybrid_metrics)
print_report(y_test_event, ypred_hybrid, le_event, "Hybrid Event", os.path.join(OUTPUT_DIR,"hybrid_event_report.txt"))

# ------------------------
# BiLSTM + Attention baseline (optional, slow)
# ------------------------
USE_BILSTM = True
bilstm_metrics = None
if USE_BILSTM:
    try:
        from tensorflow.keras.preprocessing.text import Tokenizer
        from tensorflow.keras.preprocessing.sequence import pad_sequences
        from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, Input
        from tensorflow.keras.models import Model
        from tensorflow.keras import backend as K
        MAX_SEQ_LEN_BI = 200 # Separate max_seq_len for BiLSTM
        tokenizer_bi = Tokenizer(num_words=20000, oov_token="<OOV>")
        tokenizer_bi.fit_on_texts(train_df['News_clean'])
        Xtr_seq = tokenizer_bi.texts_to_sequences(train_df['News_clean'])
        Xte_seq = tokenizer_bi.texts_to_sequences(test_df['News_clean'])
        Xtr_pad = pad_sequences(Xtr_seq, maxlen=MAX_SEQ_LEN_BI)
        Xte_pad = pad_sequences(Xte_seq, maxlen=MAX_SEQ_LEN_BI)
        n_classes = n_events

        # Attention layer
        from tensorflow.keras.layers import Layer
        class AttentionLayer(Layer):
            def build(self, input_shape):
                self.W = self.add_weight(name="att_weight", shape=(input_shape[-1],1), initializer="random_normal", trainable=True)
                super().build(input_shape)
            def call(self, inputs):
                e = K.tanh(K.dot(inputs, self.W))  # (batch, seq_len, 1)
                a = K.softmax(e, axis=1)
                weighted = inputs * a
                return K.sum(weighted, axis=1)

        inp = Input(shape=(MAX_SEQ_LEN_BI,), dtype=tf.int32)
        emb = Embedding(input_dim=min(len(tokenizer_bi.word_index)+1,20000), output_dim=128, input_length=MAX_SEQ_LEN_BI)(inp)
        x = Bidirectional(LSTM(64, return_sequences=True))(emb)
        x = AttentionLayer()(x)
        x = Dropout(0.3)(x)
        out = Dense(n_classes, activation='softmax')(x)
        model_bilstm = Model(inp, out)
        model_bilstm.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
        model_bilstm.fit(Xtr_pad, y_train_event, validation_split=0.1, epochs=30, batch_size=32, verbose=1)
        ypred_bilstm = model_bilstm.predict(Xte_pad).argmax(axis=1)
        bilstm_metrics = compute_metrics(y_test_event, ypred_bilstm)
        print("BiLSTM+Attention event metrics:", bilstm_metrics)
        print_report(y_test_event, ypred_bilstm, le_event, "BiLSTM Event", os.path.join(OUTPUT_DIR,"bilstm_event_report.txt"))
    except Exception as e:
        print("BiLSTM failed:", e)

# ------------------------
# FinBERT baseline (embedding + LR)
# ------------------------
print("Loading FinBERT (this may take a while)...")
tokenizer_fb = AutoTokenizer.from_pretrained(FINBERT_MODEL)
model_fb = TFAutoModel.from_pretrained(FINBERT_MODEL)

def embed_texts(texts, tokenizer, model, batch_size=16):
    emb_list=[]
    for i in range(0,len(texts),batch_size):
        batch = texts[i:i+batch_size]
        enc = tokenizer(batch.tolist(), padding=True, truncation=True, max_length=MAX_SEQ_LEN, return_tensors="tf")
        outputs = model(enc)
        pooled = outputs.last_hidden_state[:,0,:].numpy()
        emb_list.append(pooled)
    return np.vstack(emb_list)

X_train_fb = embed_texts(train_df['News_clean'], tokenizer_fb, model_fb, batch_size=16)
X_test_fb = embed_texts(test_df['News_clean'], tokenizer_fb, model_fb, batch_size=16)

finbert_clf = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)
finbert_clf.fit(X_train_fb, y_train_event)
ypred_finbert = finbert_clf.predict(X_test_fb)
finbert_metrics = compute_metrics(y_test_event, ypred_finbert)
print("FinBERT baseline (embed + LR) event metrics:", finbert_metrics)
print_report(y_test_event, ypred_finbert, le_event, "FinBERT Event", os.path.join(OUTPUT_DIR,"finbert_event_report.txt"))

# ------------------------
# Proposed: Multitask Context-Engineered Agentic AI (FinBERT backbone + fused features)
# Build a Keras model: FinBERT encoder -> pooled -> concat with rules+lex -> two heads
# ------------------------
print("Building Proposed Multitask Transformer (FinBERT backbone) ...")

tokenizer = tokenizer_fb  # reuse finbert tokenizer
tf_backbone = model_fb    # TFAutoModel already loaded

# Prepare inputs tokens for train/val/test
def tokenize_for_tf(texts):
    enc = tokenizer(texts.tolist(), padding='max_length', truncation=True, max_length=MAX_SEQ_LEN, return_tensors="tf")
    return enc['input_ids'], enc['attention_mask']

train_input_ids, train_attention = tokenize_for_tf(train_df['News_clean'])
val_input_ids, val_attention = tokenize_for_tf(val_df['News_clean'])
test_input_ids, test_attention = tokenize_for_tf(test_df['News_clean'])

# Prepare context features arrays
train_rules_arr = np.asarray(train_rules, dtype=np.float32)
val_rules_arr = np.asarray(val_rules, dtype=np.float32)
test_rules_arr = np.asarray(test_rules, dtype=np.float32)

train_lex_arr = np.asarray(train_df['lex_score']).reshape(-1,1).astype(np.float32)
val_lex_arr = np.asarray(val_df['lex_score']).reshape(-1,1).astype(np.float32)
test_lex_arr = np.asarray(test_df['lex_score']).reshape(-1,1).astype(np.float32)

# Normalize lex score
sc_lex = StandardScaler()
train_lex_arr = sc_lex.fit_transform(train_lex_arr)
val_lex_arr = sc_lex.transform(val_lex_arr)
test_lex_arr = sc_lex.transform(test_lex_arr)

# Custom layer to wrap the TFAutoModel call
class TransformerEncoderLayer(Layer):
    def __init__(self, transformer_model, **kwargs):
        super().__init__(**kwargs)
        self.transformer_model = transformer_model

    def call(self, inputs):
        # inputs is expected to be a list/tuple of tensors: (input_ids, attention_mask)
        input_ids, attention_mask = inputs
        # Call the underlying transformer model with the tensors directly
        outputs = self.transformer_model({'input_ids': input_ids, 'attention_mask': attention_mask})
        # Return the pooled output ([CLS] token representation)
        return outputs.last_hidden_state[:, 0, :]

# Keras model definition
# Inputs
input_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name="input_ids")
attention_mask = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name="attention_mask")
rules_input = Input(shape=(train_rules_arr.shape[1],), dtype=tf.float32, name="rules_input")
lex_input = Input(shape=(1,), dtype=tf.float32, name="lex_input")

# Instantiate the custom layer with the loaded TFAutoModel
transformer_layer = TransformerEncoderLayer(tf_backbone)

# Obtain transformer outputs by calling the custom layer with the input tensors
transformer_output = transformer_layer((input_ids, attention_mask))


# Optionally, add a small MLP to pooled output (now from the custom layer)
pooled_norm = LayerNormalization()(transformer_output)
pooled_dense = Dense(256, activation='relu')(pooled_norm)
pooled_drop = Dropout(0.2)(pooled_dense)

# Concatenate context-engineered features
context_concat = Concatenate()([pooled_drop, rules_input, lex_input])
context_dense = Dense(128, activation='relu')(context_concat)
context_drop = Dropout(0.2)(context_dense)

# Two heads: event (n_events), sentiment (n_sents)
event_logits = Dense(n_events, activation='softmax', name='event_output')(context_drop)
sent_logits = Dense(n_sents, activation='softmax', name='sent_output')(context_drop)

model = Model(inputs=[input_ids, attention_mask, rules_input, lex_input], outputs=[event_logits, sent_logits])
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss={'event_output': 'sparse_categorical_crossentropy', 'sent_output': 'sparse_categorical_crossentropy'},
    loss_weights={'event_output': 1.0, 'sent_output': 1.0},
    metrics={'event_output': tf.keras.metrics.SparseCategoricalAccuracy(), 'sent_output': tf.keras.metrics.SparseCategoricalAccuracy()}
)
model.summary()

# Prepare dataset
train_dataset = tf.data.Dataset.from_tensor_slices((
    (train_input_ids, train_attention, train_rules_arr, train_lex_arr),
    (y_train_event, y_train_sent)
)).shuffle(1024, seed=SEED).batch(BATCH_SIZE)

val_dataset = tf.data.Dataset.from_tensor_slices((
    (val_input_ids, val_attention, val_rules_arr, val_lex_arr),
    (y_val_event, y_val_sent)
)).batch(BATCH_SIZE)

test_dataset = tf.data.Dataset.from_tensor_slices((
    (test_input_ids, test_attention, test_rules_arr, test_lex_arr),
    (y_test_event, y_test_sent)
)).batch(BATCH_SIZE)


# Train
print("Training multitask model (this may take time)...")
history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)

# Predict on test
preds = model.predict(test_dataset)
event_preds = np.argmax(preds[0], axis=1)
sent_preds = np.argmax(preds[1], axis=1)

# Metrics: event and sentiment
event_metrics = compute_metrics(y_test_event, event_preds)
sent_metrics = compute_metrics(y_test_sent, sent_preds)

print("Proposed Multitask model - Event metrics:", event_metrics)
print("Proposed Multitask model - Sentiment metrics:", sent_metrics)

# Classification reports (per-class)
print_report(y_test_event, event_preds, le_event, "Proposed Event", os.path.join(OUTPUT_DIR,"proposed_event_report.txt"))
print_report(y_test_sent, sent_preds, le_sent, "Proposed Sentiment", os.path.join(OUTPUT_DIR,"proposed_sent_report.txt"))

# Save predictions
test_out = test_df.copy().reset_index(drop=True)
test_out['pred_event_proposed'] = le_event.inverse_transform(event_preds)
test_out['pred_sent_proposed'] = le_sent.inverse_transform(sent_preds)
test_out.to_csv(os.path.join(OUTPUT_DIR, "test_predictions_proposed_multitask.csv"), index=False)
print("Saved test predictions:", os.path.join(OUTPUT_DIR, "test_predictions_proposed_multitask.csv"))

# ------------------------
# Summarize all model metrics
# ------------------------
summary = {
    'NB_TFIDF_event': nb_metrics,
    'SVM_TFIDF_event': svc_metrics,
    'Hybrid_event': hybrid_metrics,
    'FinBERT_embed_event': finbert_metrics,
    'Proposed_multitask_event': event_metrics,
    'Proposed_multitask_sentiment': sent_metrics
}
pd.DataFrame(summary).T.round(3).to_csv(os.path.join(OUTPUT_DIR, "all_model_metrics.csv"))
print("All model metrics saved to", os.path.join(OUTPUT_DIR, "all_model_metrics.csv"))

# End
print("Done. Outputs in folder:", OUTPUT_DIR)

# ===========================
# Visualization of Training
# ===========================

import matplotlib.pyplot as plt

# Plot Event classification loss
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['event_output_loss'], label='Train Event Loss')
plt.plot(history.history['val_event_output_loss'], label='Val Event Loss')
plt.title("Event Classification Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()

# Plot Sentiment classification loss
plt.subplot(1,2,2)
plt.plot(history.history['sent_output_loss'], label='Train Sentiment Loss')
plt.plot(history.history['val_sent_output_loss'], label='Val Sentiment Loss')
plt.title("Sentiment Classification Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

# Plot Event classification accuracy
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(history.history['event_output_sparse_categorical_accuracy'], label='Train Event Acc') # Corrected metric name
plt.plot(history.history['val_event_output_sparse_categorical_accuracy'], label='Val Event Acc') # Corrected metric name
plt.title("Event Classification Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()

# Plot Sentiment classification accuracy
plt.subplot(1,2,2)
plt.plot(history.history['sent_output_sparse_categorical_accuracy'], label='Train Sentiment Acc') # Corrected metric name
plt.plot(history.history['val_sent_output_sparse_categorical_accuracy'], label='Val Sentiment Acc') # Corrected metric name
plt.title("Sentiment Classification Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

from google.colab import files
import os

output_files = [
    'all_model_metrics.csv',
    'test_predictions_proposed_multitask.csv',
    'nb_event_report.txt',
    'svc_event_report.txt',
    'hybrid_event_report.txt',
    'finbert_event_report.txt',
    'proposed_event_report.txt',
    'proposed_sent_report.txt'
]

for file_name in output_files:
    file_path = os.path.join('experiment_outputs', file_name)
    if os.path.exists(file_path):
        files.download(file_path)
        print(f"Downloaded {file_name}")
    else:
        print(f"File not found: {file_path}")

"""Updated"""

# Full Colab script: Dynamic lexicon + multitask Context-Engineered Agentic AI + baselines
# Paste into a single Colab cell and run. Upload your dataset when prompted.

!pip install -q transformers tensorflow scikit-learn pandas sentence-transformers openpyxl

import os, re, random, json
from collections import Counter
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.utils import resample
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from scipy.sparse import hstack, csr_matrix

from transformers import AutoTokenizer, TFAutoModel

# Optional retrieval (not used by default)
try:
    from sentence_transformers import SentenceTransformer
    S2V_AVAILABLE = True
except Exception:
    S2V_AVAILABLE = False

# ------------------------
# Config
# ------------------------
SEED = 42
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

INPUT_FILE = None   # set to path or leave None to upload in Colab
OUTPUT_DIR = "experiment_outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

SPLIT_MODE = "stratified"   # 'temporal' or 'stratified'
TEST_SIZE = 0.30
BALANCE_TRAIN = True        # oversample training set only
TFIDF_MAX_FEATURES = 5000
TOP_K_TRIGGERS = 30        # tokens per sentiment class for dynamic lexicon
FINBERT_MODEL = "ProsusAI/finbert"
MAX_SEQ_LEN = 192
BATCH_SIZE = 8
EPOCHS = 30                # per your request
LEARNING_RATE = 2e-5
USE_RETRIEVAL_CONTEXT = False

# ------------------------
# Helpers
# ------------------------
def clean_text(s):
    s = "" if pd.isna(s) else str(s)
    s = s.lower()
    s = re.sub(r'\s+', ' ', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    return s.strip()

def compute_metrics(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec_micro = precision_score(y_true, y_pred, average='micro', zero_division=0)
    rec_micro = recall_score(y_true, y_pred, average='micro', zero_division=0)
    f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)
    prec_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)
    rec_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)
    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)
    return {
        'accuracy': acc,
        'micro_precision': prec_micro, 'micro_recall': rec_micro, 'micro_f1': f1_micro,
        'macro_precision': prec_macro, 'macro_recall': rec_macro, 'macro_f1': f1_macro
    }

def print_report(y_true, y_pred, label_encoder, title, out_path=None):
    labels = list(label_encoder.classes_)
    report = classification_report(y_true, y_pred, target_names=labels, zero_division=0)
    header = f"=== Report: {title} ===\n"
    print(header + report)
    if out_path:
        with open(out_path, "w") as f:
            f.write(header)
            f.write(report)
    return report

def balance_training_set(df, label_col='Label'):
    max_n = df[label_col].value_counts().max()
    parts = []
    for lbl, g in df.groupby(label_col):
        if len(g) < max_n:
            parts.append(resample(g, replace=True, n_samples=max_n, random_state=SEED))
        else:
            parts.append(g)
    df_bal = pd.concat(parts).sample(frac=1, random_state=SEED).reset_index(drop=True)
    return df_bal

# ------------------------
# Upload dataset (Colab)
# ------------------------
from google.colab import files
if INPUT_FILE and os.path.exists(INPUT_FILE):
    file_path = INPUT_FILE
else:
    print("Upload your dataset Excel (News_event_sentiment_labeled.xlsx)...")
    uploaded = files.upload()
    file_path = list(uploaded.keys())[0]

print("Loading:", file_path)
df = pd.read_excel(file_path)
print("Raw shape:", df.shape, "Columns:", df.columns.tolist())

assert {'News','Label','Sentiment'}.issubset(set(df.columns)), "Dataset must contain News, Label, Sentiment columns"

# ------------------------
# Preprocess / split
# ------------------------
df = df.dropna(subset=['News','Label','Sentiment']).reset_index(drop=True)
df['News_clean'] = df['News'].apply(clean_text)
if 'Date' in df.columns:
    df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce')
    df.loc[df['Date_parsed'].isna(), 'Date_parsed'] = pd.date_range('2017-01-01', periods=df['Date_parsed'].isna().sum())
else:
    df['Date_parsed'] = pd.date_range('2017-01-01', periods=len(df), freq='D')

if SPLIT_MODE == 'temporal':
    df = df.sort_values('Date_parsed').reset_index(drop=True)
    n = len(df)
    train_end = int(0.7 * n)
    val_end = train_end + int(0.15 * n)
    train_df = df.iloc[:train_end].reset_index(drop=True)
    val_df = df.iloc[train_end:val_end].reset_index(drop=True)
    test_df = df.iloc[val_end:].reset_index(drop=True)
else:
    train_df, temp_df = train_test_split(df, test_size=TEST_SIZE, random_state=SEED, stratify=df['Label'])
    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['Label'])

print("Split sizes: train", len(train_df), "val", len(val_df), "test", len(test_df))

if BALANCE_TRAIN:
    train_df = balance_training_set(train_df, label_col='Label')
    print("Balanced train counts:\n", train_df['Label'].value_counts())

# Label encoders
le_event = LabelEncoder().fit(df['Label'].astype(str))
le_sent = LabelEncoder().fit(df['Sentiment'].astype(str))
n_events = len(le_event.classes_)
n_sents = len(le_sent.classes_)
print("Event classes:", n_events, "Sentiment classes:", n_sents)

y_train_event = le_event.transform(train_df['Label'])
y_val_event = le_event.transform(val_df['Label'])
y_test_event = le_event.transform(test_df['Label'])
y_train_sent = le_sent.transform(train_df['Sentiment'])
y_val_sent = le_sent.transform(val_df['Sentiment'])
y_test_sent = le_sent.transform(test_df['Sentiment'])

# ------------------------
# Dynamic sentiment lexicons (training set only)
# ------------------------
def build_dynamic_lexicons(train_df, text_col='News_clean', sent_col='Sentiment', top_k=TOP_K_TRIGGERS):
    sent_classes = train_df[sent_col].astype(str).unique()
    texts_by_sent = {}
    for s in sent_classes:
        texts_by_sent[s] = " ".join(train_df.loc[train_df[sent_col] == s, text_col].tolist())
    docs = [texts_by_sent[s] for s in sent_classes]
    cv = CountVectorizer(stop_words='english', max_features=5000)
    X = cv.fit_transform(docs)
    vocab = np.array(cv.get_feature_names_out())
    lexicons = {}
    for i, s in enumerate(sent_classes):
        freqs = np.array(X[i].todense()).flatten()
        top_idx = freqs.argsort()[-top_k:][::-1]
        top_tokens = [t for t in vocab[top_idx] if len(t) > 2]
        lexicons[s] = top_tokens
    return lexicons

lexicons = build_dynamic_lexicons(train_df, text_col='News_clean', sent_col='Sentiment', top_k=TOP_K_TRIGGERS)
print("Dynamic lexicons keys:", list(lexicons.keys()))
for k, v in lexicons.items():
    print(f"{k} : {v[:10]}")

# Create three sets if possible
POS_LEX=set(); NEG_LEX=set(); NEU_LEX=set()
for s,toks in lexicons.items():
    s_low = s.lower()
    if 'pos' in s_low or 'positive' in s_low:
        POS_LEX.update(toks)
    elif 'neg' in s_low or 'negative' in s_low:
        NEG_LEX.update(toks)
    elif 'neu' in s_low or 'neutral' in s_low:
        NEU_LEX.update(toks)
# fallback assignment
keys = list(lexicons.keys())
if not POS_LEX and keys:
    POS_LEX.update(lexicons[keys[0]])
if not NEG_LEX and len(keys)>1:
    NEG_LEX.update(lexicons[keys[1]])
if not NEU_LEX and len(keys)>2:
    NEU_LEX.update(lexicons[keys[2]])

def lexicon_score_dynamic(text):
    toks = clean_text(text).split()
    if len(toks)==0: return 0.0
    pos = sum(1 for t in toks if t in POS_LEX)
    neg = sum(1 for t in toks if t in NEG_LEX)
    neu = sum(1 for t in toks if t in NEU_LEX)
    return (pos - neg + 0.3*neu) / (len(toks)+1e-9)

train_df['lex_score'] = train_df['News_clean'].apply(lexicon_score_dynamic)
val_df['lex_score'] = val_df['News_clean'].apply(lexicon_score_dynamic)
test_df['lex_score'] = test_df['News_clean'].apply(lexicon_score_dynamic)

# Map lex score to sentiment index (closest mean)
sent_mean_scores = train_df.groupby('Sentiment')['lex_score'].mean().to_dict()
sent_labels = list(sent_mean_scores.keys())
sent_means = np.array([sent_mean_scores[s] for s in sent_labels])
def map_score_to_sentiment_idx(score):
    diffs = np.abs(sent_means - score)
    chosen = sent_labels[int(np.argmin(diffs))]
    return int(le_sent.transform([chosen])[0])

# ------------------------
# Build rule flags (context-engineered)
# ------------------------
def build_rule_flags(series):
    rows=[]
    for t in series:
        s = clean_text(t)
        rows.append([
            int("repo" in s or "rate hike" in s or "rate cut" in s or "reverse repo" in s),
            int("downgrade" in s or "upgrade" in s or "rating" in s),
            int("fraud" in s or "scam" in s or "npa" in s or "forg" in s),
            int("merger" in s or "acquir" in s or "takeover" in s),
            int("quarter" in s or "earnings" in s or "results" in s or "profit" in s)
        ])
    return np.array(rows, dtype=int)

train_rules = build_rule_flags(train_df['News'])
val_rules = build_rule_flags(val_df['News'])
test_rules = build_rule_flags(test_df['News'])

# ------------------------
# TF-IDF for classical baselines
# ------------------------
tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=(1,2), stop_words='english')
X_train_tfidf = tfidf.fit_transform(train_df['News_clean'])
X_val_tfidf = tfidf.transform(val_df['News_clean'])
X_test_tfidf = tfidf.transform(test_df['News_clean'])

# ------------------------
# Unified evaluate_and_report
# ------------------------
def evaluate_and_report(model_name, y_true_event=None, y_pred_event=None, y_true_sent=None, y_pred_sent=None):
    res = {}
    if y_pred_event is not None and y_true_event is not None:
        m_e = compute_metrics(y_true_event, y_pred_event)
        print_report(y_true_event, y_pred_event, le_event, f"{model_name} - Event", os.path.join(OUTPUT_DIR, f"{model_name}_event_report.txt"))
        res[f"{model_name}_event"] = m_e
    if y_pred_sent is not None and y_true_sent is not None:
        m_s = compute_metrics(y_true_sent, y_pred_sent)
        print_report(y_true_sent, y_pred_sent, le_sent, f"{model_name} - Sentiment", os.path.join(OUTPUT_DIR, f"{model_name}_sent_report.txt"))
        res[f"{model_name}_sentiment"] = m_s
    return res

all_summaries = {}

# ------------------------
# Lexicon baseline (dynamic)
# ------------------------
print("\n=== Lexicon (dynamic) baseline ===")
lex_preds = [map_score_to_sentiment_idx(s) for s in test_df['lex_score']]
lex_res = evaluate_and_report("LexiconDynamic", None, None, y_test_sent, lex_preds)
all_summaries.update(lex_res)

# ------------------------
# MultinomialNB baseline (TF-IDF) - both tasks
# ------------------------
print("\n=== MultinomialNB (TF-IDF) ===")
nb_event = MultinomialNB()
nb_event.fit(X_train_tfidf, y_train_event)
ypred_nb_event = nb_event.predict(X_test_tfidf)

nb_sent = MultinomialNB()
nb_sent.fit(X_train_tfidf, y_train_sent)
ypred_nb_sent = nb_sent.predict(X_test_tfidf)

nb_res = evaluate_and_report("NaiveBayes", y_test_event, ypred_nb_event, y_test_sent, ypred_nb_sent)
all_summaries.update(nb_res)

# ------------------------
# SVM baseline (TF-IDF) - both tasks
# ------------------------
print("\n=== SVM (TF-IDF) ===")
svc_event = LinearSVC(class_weight='balanced', max_iter=2000, random_state=SEED)
clf_event = CalibratedClassifierCV(svc_event)
clf_event.fit(X_train_tfidf, y_train_event)
ypred_svc_event = clf_event.predict(X_test_tfidf)

svc_sent = LinearSVC(class_weight='balanced', max_iter=2000, random_state=SEED)
clf_sent = CalibratedClassifierCV(svc_sent)
clf_sent.fit(X_train_tfidf, y_train_sent)
ypred_svc_sent = clf_sent.predict(X_test_tfidf)

svc_res = evaluate_and_report("SVM", y_test_event, ypred_svc_event, y_test_sent, ypred_svc_sent)
all_summaries.update(svc_res)

# ------------------------
# Hybrid baseline (TF-IDF + rules + dynamic lex) - both tasks
# ------------------------
print("\n=== Hybrid (TF-IDF + rules + lex) ===")
scaler = StandardScaler()
Xtr_lex = scaler.fit_transform(train_df[['lex_score']])
Xte_lex = scaler.transform(test_df[['lex_score']])
X_train_hybrid = hstack([X_train_tfidf, csr_matrix(train_rules), csr_matrix(Xtr_lex)])
X_test_hybrid = hstack([X_test_tfidf, csr_matrix(test_rules), csr_matrix(Xte_lex)])

hybrid_event = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear', random_state=SEED)
hybrid_event.fit(X_train_hybrid, y_train_event)
ypred_hybrid_event = hybrid_event.predict(X_test_hybrid)

hybrid_sent = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear', random_state=SEED)
hybrid_sent.fit(X_train_hybrid, y_train_sent)
ypred_hybrid_sent = hybrid_sent.predict(X_test_hybrid)

hybrid_res = evaluate_and_report("Hybrid", y_test_event, ypred_hybrid_event, y_test_sent, ypred_hybrid_sent)
all_summaries.update(hybrid_res)

# ------------------------
# BiLSTM-Attention baseline (multi-head for event+sent)
# ------------------------
print("\n=== BiLSTM+Attention (multi-head) ===")
bilstm_res = {}
try:
    from tensorflow.keras.preprocessing.text import Tokenizer
    from tensorflow.keras.preprocessing.sequence import pad_sequences
    from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, Input
    from tensorflow.keras.models import Model
    from tensorflow.keras import backend as K

    MAX_SEQ_LEN_BI = 200
    tokenizer_bi = Tokenizer(num_words=20000, oov_token="<OOV>")
    tokenizer_bi.fit_on_texts(train_df['News_clean'])
    Xtr_seq = tokenizer_bi.texts_to_sequences(train_df['News_clean'])
    Xte_seq = tokenizer_bi.texts_to_sequences(test_df['News_clean'])
    Xva_seq = tokenizer_bi.texts_to_sequences(val_df['News_clean'])
    Xtr_pad = pad_sequences(Xtr_seq, maxlen=MAX_SEQ_LEN_BI)
    Xte_pad = pad_sequences(Xte_seq, maxlen=MAX_SEQ_LEN_BI)
    Xva_pad = pad_sequences(Xva_seq, maxlen=MAX_SEQ_LEN_BI)

    class AttentionLayer(tf.keras.layers.Layer):
        def build(self, input_shape):
            self.W = self.add_weight(name="att_weight", shape=(input_shape[-1],1), initializer="random_normal", trainable=True)
            super().build(input_shape)
        def call(self, inputs):
            e = K.tanh(K.dot(inputs, self.W))  # (batch, seq_len, 1)
            a = K.softmax(e, axis=1)
            weighted = inputs * a
            return K.sum(weighted, axis=1)

    inp = Input(shape=(MAX_SEQ_LEN_BI,), dtype=tf.int32, name="bilstm_input")
    emb = Embedding(input_dim=min(len(tokenizer_bi.word_index)+1,20000), output_dim=128, input_length=MAX_SEQ_LEN_BI)(inp)
    x = Bidirectional(LSTM(64, return_sequences=True))(emb)
    x_att = AttentionLayer()(x)
    x_drop = Dropout(0.3)(x_att)

    # two heads
    event_out = Dense(n_events, activation='softmax', name='event_output')(x_drop)
    sent_out = Dense(n_sents, activation='softmax', name='sent_output')(x_drop)

    model_bilstm = Model(inputs=inp, outputs=[event_out, sent_out])
    model_bilstm.compile(optimizer='adam',
                         loss={'event_output': 'sparse_categorical_crossentropy', 'sent_output': 'sparse_categorical_crossentropy'},
                         metrics={'event_output': 'accuracy', 'sent_output': 'accuracy'})

    history_bi = model_bilstm.fit(Xtr_pad, [y_train_event, y_train_sent], validation_data=(Xva_pad, [y_val_event, y_val_sent]),
                                  epochs=30, batch_size=32, verbose=1)
    preds_bi = model_bilstm.predict(Xte_pad)
    pred_bi_event = np.argmax(preds_bi[0], axis=1)
    pred_bi_sent = np.argmax(preds_bi[1], axis=1)
    bilstm_res = evaluate_and_report("BiLSTM", y_test_event, pred_bi_event, y_test_sent, pred_bi_sent)
    all_summaries.update(bilstm_res)
except Exception as e:
    print("BiLSTM failed/skipped:", e)

# ------------------------
# FinBERT embeddings + LR baseline (both tasks)
# ------------------------
print("\n=== FinBERT embeddings + LR (both tasks) ===")
tokenizer_fb = AutoTokenizer.from_pretrained(FINBERT_MODEL)
model_fb = TFAutoModel.from_pretrained(FINBERT_MODEL)

def embed_texts(texts, tokenizer, model, batch_size=16):
    emb_list=[]
    for i in range(0,len(texts),batch_size):
        batch = texts[i:i+batch_size]
        enc = tokenizer(batch.tolist(), padding=True, truncation=True, max_length=MAX_SEQ_LEN, return_tensors="tf")
        outputs = model(enc)
        pooled = outputs.last_hidden_state[:,0,:].numpy()
        emb_list.append(pooled)
    return np.vstack(emb_list)

X_train_fb = embed_texts(train_df['News_clean'], tokenizer_fb, model_fb, batch_size=16)
X_test_fb = embed_texts(test_df['News_clean'], tokenizer_fb, model_fb, batch_size=16)

finbert_event = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)
finbert_event.fit(X_train_fb, y_train_event)
ypred_finbert_event = finbert_event.predict(X_test_fb)

finbert_sent = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)
finbert_sent.fit(X_train_fb, y_train_sent)
ypred_finbert_sent = finbert_sent.predict(X_test_fb)

finbert_res = evaluate_and_report("FinBERT_embed", y_test_event, ypred_finbert_event, y_test_sent, ypred_finbert_sent)
all_summaries.update(finbert_res)

# ------------------------
# Proposed: Multitask Context-Engineered Agentic AI (FinBERT backbone + fused features)
# ------------------------
print("\n=== Proposed Multitask Context-Engineered Agentic AI ===")
tokenizer = tokenizer_fb
tf_backbone = model_fb

def tokenize_texts(texts):
    enc = tokenizer(texts.tolist(), padding='max_length', truncation=True, max_length=MAX_SEQ_LEN, return_tensors="tf")
    return enc['input_ids'], enc['attention_mask']

train_input_ids, train_attention = tokenize_texts(train_df['News_clean'])
val_input_ids, val_attention = tokenize_texts(val_df['News_clean'])
test_input_ids, test_attention = tokenize_texts(test_df['News_clean'])

train_rules_arr = train_rules.astype(np.float32)
val_rules_arr = val_rules.astype(np.float32)
test_rules_arr = test_rules.astype(np.float32)
train_lex_arr = np.asarray(train_df['lex_score']).reshape(-1,1).astype(np.float32)
val_lex_arr = np.asarray(val_df['lex_score']).reshape(-1,1).astype(np.float32)
test_lex_arr = np.asarray(test_df['lex_score']).reshape(-1,1).astype(np.float32)
sc_lex = StandardScaler()
train_lex_arr = sc_lex.fit_transform(train_lex_arr)
val_lex_arr = sc_lex.transform(val_lex_arr)
test_lex_arr = sc_lex.transform(test_lex_arr)

# Transformer wrapper layer
class TransformerEncoderLayer(tf.keras.layers.Layer):
    def __init__(self, transformer_model, **kwargs):
        super().__init__(**kwargs)
        self.transformer_model = transformer_model
    def call(self, inputs):
        input_ids, attention_mask = inputs
        outputs = self.transformer_model({'input_ids': input_ids, 'attention_mask': attention_mask})
        return outputs.last_hidden_state[:,0,:]

from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, LayerNormalization
from tensorflow.keras.models import Model

input_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name="input_ids")
attention_mask = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name="attention_mask")
rules_input = Input(shape=(train_rules_arr.shape[1],), dtype=tf.float32, name="rules_input")
lex_input = Input(shape=(1,), dtype=tf.float32, name="lex_input")

transformer_layer = TransformerEncoderLayer(tf_backbone)
transformer_output = transformer_layer((input_ids, attention_mask))

pooled_norm = LayerNormalization()(transformer_output)
pooled_dense = Dense(256, activation='relu')(pooled_norm)
pooled_drop = Dropout(0.2)(pooled_dense)

context_concat = Concatenate()([pooled_drop, rules_input, lex_input])
context_dense = Dense(128, activation='relu')(context_concat)
context_drop = Dropout(0.2)(context_dense)

event_logits = Dense(n_events, activation='softmax', name='event_output')(context_drop)
sent_logits = Dense(n_sents, activation='softmax', name='sent_output')(context_drop)

model = Model(inputs=[input_ids, attention_mask, rules_input, lex_input], outputs=[event_logits, sent_logits])
model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss={'event_output': 'sparse_categorical_crossentropy', 'sent_output': 'sparse_categorical_crossentropy'},
    loss_weights={'event_output': 1.0, 'sent_output': 1.0},
    metrics={'event_output': tf.keras.metrics.SparseCategoricalAccuracy(), 'sent_output': tf.keras.metrics.SparseCategoricalAccuracy()}
)
model.summary()

# Prepare datasets
train_dataset = tf.data.Dataset.from_tensor_slices((
    {'input_ids': train_input_ids, 'attention_mask': train_attention, 'rules_input': train_rules_arr, 'lex_input': train_lex_arr},
    {'event_output': y_train_event, 'sent_output': y_train_sent}
)).shuffle(1024, seed=SEED).batch(BATCH_SIZE)

val_dataset = tf.data.Dataset.from_tensor_slices((
    {'input_ids': val_input_ids, 'attention_mask': val_attention, 'rules_input': val_rules_arr, 'lex_input': val_lex_arr},
    {'event_output': y_val_event, 'sent_output': y_val_sent}
)).batch(BATCH_SIZE)

test_dataset = tf.data.Dataset.from_tensor_slices((
    {'input_ids': test_input_ids, 'attention_mask': test_attention, 'rules_input': test_rules_arr, 'lex_input': test_lex_arr},
    {'event_output': y_test_event, 'sent_output': y_test_sent}
)).batch(BATCH_SIZE)

# Train proposed multitask model
print(f"Training proposed multitask model for {EPOCHS} epochs (may take long)...")
history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)

# Predict & evaluate
preds = model.predict(test_dataset)
event_preds = np.argmax(preds[0], axis=1)
sent_preds = np.argmax(preds[1], axis=1)
proposed_res = evaluate_and_report("Proposed_Multitask", y_test_event, event_preds, y_test_sent, sent_preds)
all_summaries.update(proposed_res)

# Save test predictions
test_out = test_df.copy().reset_index(drop=True)
test_out['pred_event_proposed'] = le_event.inverse_transform(event_preds)
test_out['pred_sent_proposed'] = le_sent.inverse_transform(sent_preds)
test_out.to_csv(os.path.join(OUTPUT_DIR, "test_predictions_proposed_multitask.csv"), index=False)

# Save combined metrics
pd.DataFrame(all_summaries).T.round(3).to_csv(os.path.join(OUTPUT_DIR, "all_model_metrics.csv"))
print("Saved combined metrics to", os.path.join(OUTPUT_DIR, "all_model_metrics.csv"))

# Save confusion matrices for proposed model (Event & Sentiment)
cm_event = confusion_matrix(y_test_event, event_preds)
cm_sent = confusion_matrix(y_test_sent, sent_preds)
import seaborn as sns
plt.figure(figsize=(8,6))
sns.heatmap(cm_event, annot=True, fmt='d', xticklabels=le_event.classes_, yticklabels=le_event.classes_, cmap='Blues')
plt.title("Proposed Model - Event Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "proposed_event_confusion.png"))
plt.show()

plt.figure(figsize=(6,5))
sns.heatmap(cm_sent, annot=True, fmt='d', xticklabels=le_sent.classes_, yticklabels=le_sent.classes_, cmap='Greens')
plt.title("Proposed Model - Sentiment Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("True")
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "proposed_sent_confusion.png"))
plt.show()

print("Done — all outputs and reports are in", OUTPUT_DIR)

"""Seeks improvement"""

# Full integrated Colab script: Dynamic lexicon + multitask Context-Engineered Agentic AI + baselines
# Paste into a single Colab cell and run. You will be prompted to upload your dataset (Excel).
# Use GPU runtime for transformer training.

!pip install -q transformers tensorflow scikit-learn pandas sentence-transformers openpyxl

import os, re, random, json, sys, math
from collections import Counter
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.utils import resample
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.calibration import CalibratedClassifierCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
from scipy.sparse import hstack, csr_matrix
from transformers import AutoTokenizer, TFAutoModel

# optional
try:
    from sentence_transformers import SentenceTransformer
    S2V_AVAILABLE = True
except Exception:
    S2V_AVAILABLE = False

# ------------------------
# CONFIG
# ------------------------
SEED = 42
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

OUTPUT_DIR = "experiment_outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

SPLIT_MODE = "stratified"   # 'temporal' or 'stratified'
TEST_SIZE = 0.30
BALANCE_TRAIN = True
TFIDF_MAX_FEATURES = 5000
TOP_K_TRIGGERS = 30
FINBERT_MODEL = "ProsusAI/finbert"
MAX_SEQ_LEN = 256          # increased to capture more context
BATCH_SIZE = 8
EPOCHS = 30                # per request
LEARNING_RATE = 2e-5
FREEZE_BOTTOM_LAYERS = 8   # attempt to freeze first N transformer layers (best-effort)

# ------------------------
# HELPERS
# ------------------------
def clean_text(s):
    s = "" if pd.isna(s) else str(s)
    s = s.lower()
    s = re.sub(r'\s+', ' ', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    return s.strip()

def compute_metrics(y_true, y_pred):
    acc = accuracy_score(y_true, y_pred)
    prec_micro = precision_score(y_true, y_pred, average='micro', zero_division=0)
    rec_micro = recall_score(y_true, y_pred, average='micro', zero_division=0)
    f1_micro = f1_score(y_true, y_pred, average='micro', zero_division=0)
    prec_macro = precision_score(y_true, y_pred, average='macro', zero_division=0)
    rec_macro = recall_score(y_true, y_pred, average='macro', zero_division=0)
    f1_macro = f1_score(y_true, y_pred, average='macro', zero_division=0)
    return {
        'accuracy': acc,
        'micro_precision': prec_micro, 'micro_recall': rec_micro, 'micro_f1': f1_micro,
        'macro_precision': prec_macro, 'macro_recall': rec_macro, 'macro_f1': f1_macro
    }

def print_report(y_true, y_pred, label_encoder, title, out_path=None):
    labels = list(label_encoder.classes_)
    report = classification_report(y_true, y_pred, target_names=labels, zero_division=0)
    header = f"=== Report: {title} ===\n"
    print(header + report)
    if out_path:
        with open(out_path, "w") as f:
            f.write(header)
            f.write(report)
    return report

def balance_training_set(df, label_col='Label'):
    max_n = df[label_col].value_counts().max()
    parts = []
    for lbl, g in df.groupby(label_col):
        if len(g) < max_n:
            parts.append(resample(g, replace=True, n_samples=max_n, random_state=SEED))
        else:
            parts.append(g)
    df_bal = pd.concat(parts).sample(frac=1, random_state=SEED).reset_index(drop=True)
    return df_bal

# ------------------------
# Upload dataset (Colab)
# ------------------------
from google.colab import files
print("Upload your dataset Excel (News_event_sentiment_labeled.xlsx)...")
uploaded = files.upload()
file_path = list(uploaded.keys())[0]
print("Loaded file:", file_path)

# ------------------------
# Load & preprocess
# ------------------------
df = pd.read_excel(file_path)
print("Raw shape:", df.shape, "Columns:", df.columns.tolist())
assert {'News','Label','Sentiment'}.issubset(set(df.columns)), "Dataset must contain News, Label, Sentiment columns"

df = df.dropna(subset=['News','Label','Sentiment']).reset_index(drop=True)
df['News_clean'] = df['News'].apply(clean_text)
if 'Date' in df.columns:
    df['Date_parsed'] = pd.to_datetime(df['Date'], errors='coerce')
    df.loc[df['Date_parsed'].isna(), 'Date_parsed'] = pd.date_range('2017-01-01', periods=df['Date_parsed'].isna().sum())
else:
    df['Date_parsed'] = pd.date_range('2017-01-01', periods=len(df), freq='D')

# ------------------------
# Split
# ------------------------
if SPLIT_MODE == 'temporal':
    df = df.sort_values('Date_parsed').reset_index(drop=True)
    n = len(df)
    train_end = int(0.7 * n)
    val_end = train_end + int(0.15 * n)
    train_df = df.iloc[:train_end].reset_index(drop=True)
    val_df = df.iloc[train_end:val_end].reset_index(drop=True)
    test_df = df.iloc[val_end:].reset_index(drop=True)
else:
    train_df, temp_df = train_test_split(df, test_size=TEST_SIZE, random_state=SEED, stratify=df['Label'])
    val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['Label'])

print("Split sizes: train", len(train_df), "val", len(val_df), "test", len(test_df))

if BALANCE_TRAIN:
    train_df = balance_training_set(train_df, label_col='Label')
    print("Balanced train counts:\n", train_df['Label'].value_counts())

# ------------------------
# Label encoders & targets
# ------------------------
le_event = LabelEncoder().fit(df['Label'].astype(str))
le_sent = LabelEncoder().fit(df['Sentiment'].astype(str))
n_events = len(le_event.classes_)
n_sents = len(le_sent.classes_)
print("Event classes:", n_events, "Sentiment classes:", n_sents)

y_train_event = le_event.transform(train_df['Label'])
y_val_event = le_event.transform(val_df['Label'])
y_test_event = le_event.transform(test_df['Label'])
y_train_sent = le_sent.transform(train_df['Sentiment'])
y_val_sent = le_sent.transform(val_df['Sentiment'])
y_test_sent = le_sent.transform(test_df['Sentiment'])

# ------------------------
# Dynamic sentiment lexicon (training set only)
# ------------------------
def build_dynamic_lexicons(train_df, text_col='News_clean', sent_col='Sentiment', top_k=TOP_K_TRIGGERS):
    sent_classes = train_df[sent_col].astype(str).unique()
    texts_by_sent = {}
    for s in sent_classes:
        texts_by_sent[s] = " ".join(train_df.loc[train_df[sent_col] == s, text_col].tolist())
    docs = [texts_by_sent[s] for s in sent_classes]
    cv = CountVectorizer(stop_words='english', max_features=5000)
    if len(docs)==0:
        return {}
    X = cv.fit_transform(docs)
    vocab = np.array(cv.get_feature_names_out())
    lexicons = {}
    for i, s in enumerate(sent_classes):
        freqs = np.array(X[i].todense()).flatten()
        top_idx = freqs.argsort()[-top_k:][::-1]
        top_tokens = [t for t in vocab[top_idx] if len(t) > 2]
        lexicons[s] = top_tokens
    return lexicons

lexicons = build_dynamic_lexicons(train_df)
print("Dynamic lexicon classes:", list(lexicons.keys()))
for k,v in lexicons.items():
    print(f"{k} top tokens (sample): {v[:10]}")

# derive POS/NEG/NEU sets heuristically
POS_LEX=set(); NEG_LEX=set(); NEU_LEX=set()
for s,toks in lexicons.items():
    s_low = s.lower()
    if 'pos' in s_low or 'positive' in s_low:
        POS_LEX.update(toks)
    elif 'neg' in s_low or 'negative' in s_low:
        NEG_LEX.update(toks)
    elif 'neu' in s_low or 'neutral' in s_low:
        NEU_LEX.update(toks)
keys = list(lexicons.keys())
if not POS_LEX and keys:
    POS_LEX.update(lexicons[keys[0]])
if not NEG_LEX and len(keys)>1:
    NEG_LEX.update(lexicons[keys[1]])
if not NEU_LEX and len(keys)>2:
    NEU_LEX.update(lexicons[keys[2]])

def lexicon_score_dynamic(text):
    toks = clean_text(text).split()
    if len(toks)==0:
        return 0.0
    pos = sum(1 for t in toks if t in POS_LEX)
    neg = sum(1 for t in toks if t in NEG_LEX)
    neu = sum(1 for t in toks if t in NEU_LEX)
    return (pos - neg + 0.3*neu) / (len(toks)+1e-9)

train_df['lex_score'] = train_df['News_clean'].apply(lexicon_score_dynamic)
val_df['lex_score'] = val_df['News_clean'].apply(lexicon_score_dynamic)
test_df['lex_score'] = test_df['News_clean'].apply(lexicon_score_dynamic)

# map lex score to sentiment idx by nearest mean
sent_mean_scores = train_df.groupby('Sentiment')['lex_score'].mean().to_dict()
sent_labels = list(sent_mean_scores.keys())
sent_means = np.array([sent_mean_scores[s] for s in sent_labels])
def map_score_to_sentiment_idx(score):
    diffs = np.abs(sent_means - score)
    chosen = sent_labels[int(np.argmin(diffs))]
    return int(le_sent.transform([chosen])[0])

# ------------------------
# Context rule flags
# ------------------------
def build_rule_flags(series):
    rows=[]
    for t in series:
        s = clean_text(t)
        rows.append([
            int("repo" in s or "rate hike" in s or "rate cut" in s or "reverse repo" in s),
            int("downgrade" in s or "upgrade" in s or "rating" in s or "ratings" in s),
            int("fraud" in s or "scam" in s or "npa" in s or "forg" in s),
            int("merger" in s or "acquir" in s or "takeover" in s or "consolidat" in s),
            int("quarter" in s or "earnings" in s or "results" in s or "profit" in s)
        ])
    return np.array(rows, dtype=int)

train_rules = build_rule_flags(train_df['News'])
val_rules = build_rule_flags(val_df['News'])
test_rules = build_rule_flags(test_df['News'])

# ------------------------
# TF-IDF features for classical baselines
# ------------------------
tfidf = TfidfVectorizer(max_features=TFIDF_MAX_FEATURES, ngram_range=(1,2), stop_words='english')
X_train_tfidf = tfidf.fit_transform(train_df['News_clean'])
X_val_tfidf = tfidf.transform(val_df['News_clean'])
X_test_tfidf = tfidf.transform(test_df['News_clean'])

# ------------------------
# Unified evaluate_and_report
# ------------------------
def evaluate_and_report(model_name, y_true_event=None, y_pred_event=None, y_true_sent=None, y_pred_sent=None):
    res = {}
    if y_pred_event is not None and y_true_event is not None:
        m_e = compute_metrics(y_true_event, y_pred_event)
        print_report(y_true_event, y_pred_event, le_event, f"{model_name} - Event", os.path.join(OUTPUT_DIR, f"{model_name}_event_report.txt"))
        res[f"{model_name}_event"] = m_e
    if y_pred_sent is not None and y_true_sent is not None:
        m_s = compute_metrics(y_true_sent, y_pred_sent)
        print_report(y_true_sent, y_pred_sent, le_sent, f"{model_name} - Sentiment", os.path.join(OUTPUT_DIR, f"{model_name}_sent_report.txt"))
        res[f"{model_name}_sentiment"] = m_s
    return res

all_summaries = {}

# ------------------------
# Baseline: Lexicon dynamic (sentiment)
# ------------------------
print("\n=== Baseline: Dynamic Lexicon (sentiment) ===")
lex_preds = [map_score_to_sentiment_idx(s) for s in test_df['lex_score']]
lex_res = evaluate_and_report("LexiconDynamic", None, None, y_test_sent, lex_preds)
all_summaries.update(lex_res)

# ------------------------
# Baseline: MultinomialNB (TF-IDF) - both tasks
# ------------------------
print("\n=== Baseline: MultinomialNB (TF-IDF) ===")
nb_event = MultinomialNB(); nb_event.fit(X_train_tfidf, y_train_event); ypred_nb_event = nb_event.predict(X_test_tfidf)
nb_sent = MultinomialNB(); nb_sent.fit(X_train_tfidf, y_train_sent); ypred_nb_sent = nb_sent.predict(X_test_tfidf)
nb_res = evaluate_and_report("NaiveBayes", y_test_event, ypred_nb_event, y_test_sent, ypred_nb_sent)
all_summaries.update(nb_res)

# ------------------------
# Baseline: SVM (TF-IDF) - both tasks
# ------------------------
print("\n=== Baseline: SVM (TF-IDF) ===")
svc_event = LinearSVC(class_weight='balanced', max_iter=2000, random_state=SEED)
clf_event = CalibratedClassifierCV(svc_event); clf_event.fit(X_train_tfidf, y_train_event); ypred_svc_event = clf_event.predict(X_test_tfidf)
svc_sent = LinearSVC(class_weight='balanced', max_iter=2000, random_state=SEED)
clf_sent = CalibratedClassifierCV(svc_sent); clf_sent.fit(X_train_tfidf, y_train_sent); ypred_svc_sent = clf_sent.predict(X_test_tfidf)
svc_res = evaluate_and_report("SVM", y_test_event, ypred_svc_event, y_test_sent, ypred_svc_sent)
all_summaries.update(svc_res)

# ------------------------
# Baseline: Hybrid (TF-IDF + rules + lex) - both tasks
# ------------------------
print("\n=== Baseline: Hybrid (TF-IDF + rules + lex) ===")
scaler = StandardScaler(); Xtr_lex = scaler.fit_transform(train_df[['lex_score']]); Xte_lex = scaler.transform(test_df[['lex_score']])
X_train_hybrid = hstack([X_train_tfidf, csr_matrix(train_rules), csr_matrix(Xtr_lex)])
X_test_hybrid  = hstack([X_test_tfidf, csr_matrix(test_rules), csr_matrix(Xte_lex)])
hybrid_event = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear', random_state=SEED)
hybrid_event.fit(X_train_hybrid, y_train_event); ypred_hybrid_event = hybrid_event.predict(X_test_hybrid)
hybrid_sent = LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear', random_state=SEED)
hybrid_sent.fit(X_train_hybrid, y_train_sent); ypred_hybrid_sent = hybrid_sent.predict(X_test_hybrid)
hybrid_res = evaluate_and_report("Hybrid", y_test_event, ypred_hybrid_event, y_test_sent, ypred_hybrid_sent)
all_summaries.update(hybrid_res)

# ------------------------
# Baseline: BiLSTM+Attention multi-head (event + sentiment)
# ------------------------
print("\n=== Baseline: BiLSTM+Attention (multi-head) ===")
bilstm_res={}
try:
    from tensorflow.keras.preprocessing.text import Tokenizer
    from tensorflow.keras.preprocessing.sequence import pad_sequences
    from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense, Input
    from tensorflow.keras.models import Model
    from tensorflow.keras import backend as K

    MAX_SEQ_LEN_BI = 200
    tokenizer_bi = Tokenizer(num_words=20000, oov_token="<OOV>")
    tokenizer_bi.fit_on_texts(train_df['News_clean'])
    Xtr_seq = tokenizer_bi.texts_to_sequences(train_df['News_clean'])
    Xte_seq = tokenizer_bi.texts_to_sequences(test_df['News_clean'])
    Xva_seq = tokenizer_bi.texts_to_sequences(val_df['News_clean'])
    Xtr_pad = pad_sequences(Xtr_seq, maxlen=MAX_SEQ_LEN_BI)
    Xte_pad = pad_sequences(Xte_seq, maxlen=MAX_SEQ_LEN_BI)
    Xva_pad = pad_sequences(Xva_seq, maxlen=MAX_SEQ_LEN_BI)

    class AttentionLayer(tf.keras.layers.Layer):
        def build(self, input_shape):
            self.W = self.add_weight(name="att_weight", shape=(input_shape[-1],1), initializer="random_normal", trainable=True)
            super().build(input_shape)
        def call(self, inputs):
            e = K.tanh(K.dot(inputs, self.W))
            a = K.softmax(e, axis=1)
            weighted = inputs * a
            return K.sum(weighted, axis=1)

    inp = Input(shape=(MAX_SEQ_LEN_BI,), dtype=tf.int32)
    emb = Embedding(input_dim=min(len(tokenizer_bi.word_index)+1,20000), output_dim=128, input_length=MAX_SEQ_LEN_BI)(inp)
    x = Bidirectional(LSTM(64, return_sequences=True))(emb)
    x_att = AttentionLayer()(x)
    x_drop = Dropout(0.3)(x_att)

    event_out = Dense(n_events, activation='softmax', name='event_output')(x_drop)
    sent_out = Dense(n_sents, activation='softmax', name='sent_output')(x_drop)

    model_bilstm = Model(inputs=inp, outputs=[event_out, sent_out])
    model_bilstm.compile(optimizer='adam',
                         loss={'event_output': 'sparse_categorical_crossentropy', 'sent_output': 'sparse_categorical_crossentropy'},
                         metrics={'event_output': 'accuracy', 'sent_output': 'accuracy'})

    history_bi = model_bilstm.fit(Xtr_pad, [y_train_event, y_train_sent],
                                  validation_data=(Xva_pad, [y_val_event, y_val_sent]),
                                  epochs=30, batch_size=32, verbose=1)
    preds_bi = model_bilstm.predict(Xte_pad)
    pred_bi_event = np.argmax(preds_bi[0], axis=1)
    pred_bi_sent = np.argmax(preds_bi[1], axis=1)
    bilstm_res = evaluate_and_report("BiLSTM", y_test_event, pred_bi_event, y_test_sent, pred_bi_sent)
    all_summaries.update(bilstm_res)
except Exception as e:
    print("BiLSTM skipped/failed:", e)

# ------------------------
# Baseline: FinBERT embeddings + LR (both tasks)
# ------------------------
print("\n=== Baseline: FinBERT embeddings + LR (both tasks) ===")
tokenizer_fb = AutoTokenizer.from_pretrained(FINBERT_MODEL)
model_fb = TFAutoModel.from_pretrained(FINBERT_MODEL)

def embed_texts(texts, tokenizer, model, batch_size=16):
    emb_list=[]
    for i in range(0,len(texts),batch_size):
        batch = texts[i:i+batch_size]
        enc = tokenizer(batch.tolist(), padding=True, truncation=True, max_length=MAX_SEQ_LEN, return_tensors="tf")
        outputs = model(enc)
        pooled = outputs.last_hidden_state[:,0,:].numpy()
        emb_list.append(pooled)
    return np.vstack(emb_list)

X_train_fb = embed_texts(train_df['News_clean'], tokenizer_fb, model_fb, batch_size=16)
X_test_fb  = embed_texts(test_df['News_clean'], tokenizer_fb, model_fb, batch_size=16)

finbert_event = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)
finbert_event.fit(X_train_fb, y_train_event); ypred_finbert_event = finbert_event.predict(X_test_fb)
finbert_sent  = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=SEED)
finbert_sent.fit(X_train_fb, y_train_sent); ypred_finbert_sent = finbert_sent.predict(X_test_fb)
finbert_res = evaluate_and_report("FinBERT_embed", y_test_event, ypred_finbert_event, y_test_sent, ypred_finbert_sent)
all_summaries.update(finbert_res)

# ------------------------
# PROPOSED IMPROVED MULTITASK AGENTIC AI (FinBERT backbone + fused context)
# ------------------------
print("\n=== Proposed Improved Multitask Agentic AI ===")

# Attempt to freeze bottom layers of the transformer (best-effort)
try:
    # If model_fb is a TF model, explore its encoder layers
    model_fb.trainable = True
    # Try to find encoder layers to freeze; this varies by model implementation
    encoder_layers = [l for l in model_fb.layers if 'encoder' in l.name or 'layer' in l.name]
    if len(encoder_layers) >= FREEZE_BOTTOM_LAYERS:
        for l in encoder_layers[:FREEZE_BOTTOM_LAYERS]:
            l.trainable = False
        print(f"Froze first {FREEZE_BOTTOM_LAYERS} encoder layers (approx).")
    else:
        # fallback: freeze entire model then unfreeze top few variables if possible
        model_fb.trainable = False
        print("Could not identify separate encoder layers; froze entire backbone as fallback.")
except Exception as e:
    print("Warning while trying to freeze layers:", e)
    # safe fallback: freeze backbone
    model_fb.trainable = False

# Tokenize
def tokenize_texts(texts):
    enc = tokenizer_fb(texts.tolist(), padding='max_length', truncation=True, max_length=MAX_SEQ_LEN, return_tensors="tf")
    return enc['input_ids'], enc['attention_mask']

train_input_ids, train_attention = tokenize_texts(train_df['News_clean'])
val_input_ids, val_attention = tokenize_texts(val_df['News_clean'])
test_input_ids, test_attention = tokenize_texts(test_df['News_clean'])

train_rules_arr = train_rules.astype(np.float32)
val_rules_arr = val_rules.astype(np.float32)
test_rules_arr = test_rules.astype(np.float32)

train_lex_arr = np.asarray(train_df['lex_score']).reshape(-1,1).astype(np.float32)
val_lex_arr = np.asarray(val_df['lex_score']).reshape(-1,1).astype(np.float32)
test_lex_arr = np.asarray(test_df['lex_score']).reshape(-1,1).astype(np.float32)
sc_lex = StandardScaler(); train_lex_arr = sc_lex.fit_transform(train_lex_arr); val_lex_arr = sc_lex.transform(val_lex_arr); test_lex_arr = sc_lex.transform(test_lex_arr)

from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, LayerNormalization
from tensorflow.keras.models import Model
from tensorflow.keras import layers

class TransformerEncoderLayer(tf.keras.layers.Layer):
    def __init__(self, transformer_model, **kwargs):
        super().__init__(**kwargs)
        self.transformer_model = transformer_model
    def call(self, inputs):
        input_ids, attention_mask = inputs
        outputs = self.transformer_model({'input_ids': input_ids, 'attention_mask': attention_mask})
        return outputs.last_hidden_state[:,0,:]  # CLS token vector

# Inputs
input_ids_in = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name="input_ids")
attention_in = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name="attention_mask")
rules_in = Input(shape=(train_rules_arr.shape[1],), dtype=tf.float32, name="rules_input")
lex_in = Input(shape=(1,), dtype=tf.float32, name="lex_input")

# Encoder wrapper
transformer_layer = TransformerEncoderLayer(model_fb)
transformer_output = transformer_layer((input_ids_in, attention_in))
transformer_dense = Dense(256, activation='relu')(transformer_output)

# Project rules and lex
rules_dense = Dense(32, activation='relu')(rules_in)
lex_dense = Dense(16, activation='relu')(lex_in)
context_proj = Concatenate()([rules_dense, lex_dense])
context_dense = Dense(64, activation='relu')(context_proj)

# Gated fusion
gate = Dense(1, activation='sigmoid')(context_dense)   # learns weight between context and transformer
# expand gate to match transformer_dense dims
gate_expanded = layers.Dense(transformer_dense.shape[-1], activation='sigmoid')(gate)
fused = gate_expanded * transformer_dense + (1.0 - gate_expanded) * layers.Dense(transformer_dense.shape[-1], activation='relu')(context_dense)

shared = Dropout(0.3)(Dense(128, activation='relu')(fused))

event_logits = Dense(n_events, activation='softmax', name='event_output')(shared)
sent_logits = Dense(n_sents, activation='softmax', name='sent_output')(shared)

proposed_model = Model(inputs=[input_ids_in, attention_in, rules_in, lex_in], outputs=[event_logits, sent_logits])
proposed_model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
    loss={'event_output':'sparse_categorical_crossentropy', 'sent_output':'sparse_categorical_crossentropy'},
    loss_weights={'event_output':1.5, 'sent_output':1.0},
    metrics={'event_output':'accuracy','sent_output':'accuracy'}
)
proposed_model.summary()

# Datasets
train_dataset = tf.data.Dataset.from_tensor_slices((
    {'input_ids': train_input_ids, 'attention_mask': train_attention, 'rules_input': train_rules_arr, 'lex_input': train_lex_arr},
    {'event_output': y_train_event, 'sent_output': y_train_sent}
)).shuffle(1024, seed=SEED).batch(BATCH_SIZE)

val_dataset = tf.data.Dataset.from_tensor_slices((
    {'input_ids': val_input_ids, 'attention_mask': val_attention, 'rules_input': val_rules_arr, 'lex_input': val_lex_arr},
    {'event_output': y_val_event, 'sent_output': y_val_sent}
)).batch(BATCH_SIZE)

test_dataset = tf.data.Dataset.from_tensor_slices((
    {'input_ids': test_input_ids, 'attention_mask': test_attention, 'rules_input': test_rules_arr, 'lex_input': test_lex_arr},
    {'event_output': y_test_event, 'sent_output': y_test_sent}
)).batch(BATCH_SIZE)

# Train with early stopping to avoid overfitting
es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)
history = proposed_model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS, callbacks=[es])

# Predict & evaluate
preds = proposed_model.predict(test_dataset)
event_preds = np.argmax(preds[0], axis=1)
sent_preds = np.argmax(preds[1], axis=1)

prop_res = evaluate_and_report("Proposed_Improved", y_test_event, event_preds, y_test_sent, sent_preds)
all_summaries.update(prop_res)

# Save predictions
test_out = test_df.copy().reset_index(drop=True)
test_out['pred_event_proposed'] = le_event.inverse_transform(event_preds)
test_out['pred_sent_proposed'] = le_sent.inverse_transform(sent_preds)
test_out.to_csv(os.path.join(OUTPUT_DIR, "test_predictions_proposed_multitask.csv"), index=False)

# Save combined metrics
pd.DataFrame(all_summaries).T.round(3).to_csv(os.path.join(OUTPUT_DIR, "all_model_metrics.csv"))
print("Saved combined metrics to", os.path.join(OUTPUT_DIR, "all_model_metrics.csv"))

# Save confusion matrices for proposed model
cm_event = confusion_matrix(y_test_event, event_preds)
cm_sent = confusion_matrix(y_test_sent, sent_preds)

plt.figure(figsize=(8,6))
sns.heatmap(cm_event, annot=True, fmt='d', xticklabels=le_event.classes_, yticklabels=le_event.classes_, cmap='Blues')
plt.title("Proposed Model - Event Confusion Matrix")
plt.xlabel("Predicted"); plt.ylabel("True")
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "proposed_event_confusion.png"))
plt.show()

plt.figure(figsize=(6,5))
sns.heatmap(cm_sent, annot=True, fmt='d', xticklabels=le_sent.classes_, yticklabels=le_sent.classes_, cmap='Greens')
plt.title("Proposed Model - Sentiment Confusion Matrix")
plt.xlabel("Predicted"); plt.ylabel("True")
plt.tight_layout()
plt.savefig(os.path.join(OUTPUT_DIR, "proposed_sent_confusion.png"))
plt.show()

# Plot training curves (if history exists)
if history is not None:
    hist = history.history
    # Loss per head: Keras names may be 'event_output_loss' and 'sent_output_loss' or 'loss'/'val_loss'
    plt.figure(figsize=(12,5))
    # combined loss
    if 'loss' in hist:
        plt.plot(hist['loss'], label='train_loss')
        plt.plot(hist.get('val_loss', []), label='val_loss')
        plt.title("Combined Loss")
        plt.xlabel("Epoch"); plt.ylabel("Loss"); plt.legend()
        plt.show()
    # event accuracy
    if 'event_output_accuracy' in hist:
        plt.figure(figsize=(12,4))
        plt.plot(hist['event_output_accuracy'], label='train_event_acc')
        plt.plot(hist.get('val_event_output_accuracy', []), label='val_event_acc')
        plt.title("Event Accuracy")
        plt.xlabel("Epoch"); plt.ylabel("Accuracy"); plt.legend()
        plt.show()
    # sentiment accuracy
    if 'sent_output_accuracy' in hist:
        plt.figure(figsize=(12,4))
        plt.plot(hist['sent_output_accuracy'], label='train_sent_acc')
        plt.plot(hist.get('val_sent_output_accuracy', []), label='val_sent_acc')
        plt.title("Sentiment Accuracy")
        plt.xlabel("Epoch"); plt.ylabel("Accuracy"); plt.legend()
        plt.show()

print("All done. Outputs (reports, metrics, predictions) are saved under:", OUTPUT_DIR)

# ============================================
# Colab Script: Context-Engineered Agentic AI
# Event + Sentiment Classification in Banking News
# With RAG, Augmentation, Hyperparameter Tuning
# ============================================

!pip install scikit-learn pandas matplotlib seaborn tensorflow transformers sentence-transformers nlpaug keras-tuner -q

import os, re, random
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import tensorflow as tf

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
from sklearn.utils import resample

from transformers import AutoTokenizer, TFAutoModel
from sentence_transformers import SentenceTransformer
import nlpaug.augmenter.word as naw
import keras_tuner as kt

# Add NLTK download
import nltk
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
nltk.download('averaged_perceptron_tagger_eng') # Added this specific download


# ------------------------
# Config
# ------------------------
SEED = 42
random.seed(SEED); np.random.seed(SEED); tf.random.set_seed(SEED)

OUTPUT_DIR = "experiment_outputs"
os.makedirs(OUTPUT_DIR, exist_ok=True)

SPLIT_MODE = "stratified"   # 'temporal' or 'stratified'
TEST_SIZE = 0.30
BALANCE_TRAIN = True
TFIDF_MAX_FEATURES = 5000
TOP_K_TRIGGERS = 30
FINBERT_MODEL = "ProsusAI/finbert"
MAX_SEQ_LEN = 256          # increased to capture more context
BATCH_SIZE = 8
EPOCHS = 30                # per request
LEARNING_RATE = 2e-5
FREEZE_BOTTOM_LAYERS = 8   # attempt to freeze first N transformer layers (best-effort)

# ------------------------
# Utils
# ------------------------
def clean_text(s):
    s = "" if pd.isna(s) else str(s)
    s = s.lower()
    s = re.sub(r'\s+', ' ', s)
    s = re.sub(r'[^a-z0-9\s]', ' ', s)
    return s.strip()

def compute_metrics(y_true, y_pred):
    return {
        "accuracy": accuracy_score(y_true, y_pred),
        "precision_macro": precision_score(y_true, y_pred, average="macro", zero_division=0),
        "recall_macro": recall_score(y_true, y_pred, average="macro", zero_division=0),
        "f1_macro": f1_score(y_true, y_pred, average="macro", zero_division=0),
        "precision_micro": precision_score(y_true, y_pred, average="micro", zero_division=0),
        "recall_micro": recall_score(y_true, y_pred, average="micro", zero_division=0),
        "f1_micro": f1_score(y_true, y_pred, average="micro", zero_division=0),
    }

def print_report(y_true, y_pred, le, title):
    print(f"\n=== {title} Classification Report ===")
    print(classification_report(y_true, y_pred, target_names=le.classes_, zero_division=0))

def balance_training(df, label_col="Label"):
    max_n = df[label_col].value_counts().max()
    parts = []
    for lbl, g in df.groupby(label_col):
        if len(g) < max_n:
            parts.append(resample(g, replace=True, n_samples=max_n, random_state=SEED))
        else:
            parts.append(g)
    return pd.concat(parts).sample(frac=1, random_state=SEED).reset_index(drop=True)

# ------------------------
# Upload Dataset
# ------------------------
from google.colab import files
print("Upload dataset (News_event_sentiment_labeled.xlsx)...")
uploaded = files.upload()
file_path = list(uploaded.keys())[0]

df = pd.read_excel(file_path).dropna(subset=["News","Label","Sentiment"]).reset_index(drop=True)
df['News_clean'] = df['News'].apply(clean_text)
print("Loaded:", df.shape)

# ------------------------
# Data Augmentation
# ------------------------
# The SynonymAug requires the 'averaged_perceptron_tagger' and 'wordnet' NLTK data.
# These are downloaded at the top of the cell.
aug = naw.SynonymAug(aug_src="wordnet")

aug_samples = []
for i,row in df.sample(frac=0.2, random_state=SEED).iterrows():  # augment 20%
    aug_text = aug.augment(row['News'])
    aug_samples.append({"News": aug_text, "Label": row["Label"], "Sentiment": row["Sentiment"]})

aug_df = pd.DataFrame(aug_samples)
aug_df["News_clean"] = aug_df["News"].apply(clean_text)
df = pd.concat([df, aug_df]).reset_index(drop=True)
print("After augmentation:", df.shape)

# ------------------------
# Retrieval-Augmented Context (RAG-lite)
# ------------------------
retr_model = SentenceTransformer("all-MiniLM-L6-v2")
all_embs = retr_model.encode(df["News_clean"].tolist(), convert_to_tensor=True)

def enrich_with_retrieval(text, k=2):
    q_emb = retr_model.encode([text], convert_to_tensor=True)
    sims = np.inner(q_emb.cpu().numpy(), all_embs.cpu().numpy())[0]
    top_idx = sims.argsort()[-k:]
    retrieved = " ".join(df.iloc[top_idx]["News_clean"].tolist())
    return text + " [SEP] " + retrieved

df["News_enriched"] = df["News_clean"].apply(lambda x: enrich_with_retrieval(x, k=2))

# ------------------------
# Train/Val/Test Split
# ------------------------
train_df, temp_df = train_test_split(df, test_size=0.3, random_state=SEED, stratify=df['Label'])
val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=SEED, stratify=temp_df['Label'])

train_df = balance_training(train_df, label_col="Label")

# Label encoders
le_event = LabelEncoder().fit(df["Label"])
le_sent = LabelEncoder().fit(df["Sentiment"])
n_events, n_sents = len(le_event.classes_), len(le_sent.classes_)

y_train_event = le_event.transform(train_df["Label"])
y_val_event = le_event.transform(val_df["Label"])
y_test_event = le_event.transform(test_df["Label"])

y_train_sent = le_sent.transform(train_df["Sentiment"])
y_val_sent = le_sent.transform(val_df["Sentiment"])
y_test_sent = le_sent.transform(test_df["Sentiment"])

# ------------------------
# Tokenize with FinBERT
# ------------------------
tokenizer = AutoTokenizer.from_pretrained(FINBERT_MODEL)
tf_backbone = TFAutoModel.from_pretrained(FINBERT_MODEL)

def tokenize_data(texts):
    enc = tokenizer(texts.tolist(), padding="max_length", truncation=True, max_length=MAX_SEQ_LEN, return_tensors="tf")
    return enc["input_ids"], enc["attention_mask"]

train_ids, train_mask = tokenize_data(train_df["News_enriched"])
val_ids, val_mask = tokenize_data(val_df["News_enriched"])
test_ids, test_mask = tokenize_data(test_df["News_enriched"])

# ------------------------
# Build Proposed Model (with tuning)
# ------------------------
from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, Concatenate
from tensorflow.keras.models import Model

class TransformerEncoder(tf.keras.layers.Layer):
    def __init__(self, model, **kwargs):
        super().__init__(**kwargs)
        self.model = model
    def call(self, inputs):
        ids, mask = inputs
        outputs = self.model({"input_ids": ids, "attention_mask": mask})
        return outputs.last_hidden_state[:,0,:]

def build_model(hp):
    input_ids = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name="input_ids")
    att_mask = Input(shape=(MAX_SEQ_LEN,), dtype=tf.int32, name="attention_mask")

    transf = TransformerEncoder(tf_backbone)([input_ids, att_mask])
    x = LayerNormalization()(transf)
    x = Dense(hp.Int("dense_units", 128, 256, step=64), activation="relu")(x)
    x = Dropout(hp.Float("dropout", 0.1, 0.5, step=0.1))(x)

    event_out = Dense(n_events, activation="softmax", name="event_output")(x)
    sent_out = Dense(n_sents, activation="softmax", name="sent_output")(x)

    model = Model([input_ids, att_mask], [event_out, sent_out])
    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=hp.Choice("lr", [5e-5, 3e-5, 2e-5])),
        loss={"event_output":"sparse_categorical_crossentropy","sent_output":"sparse_categorical_crossentropy"},
        metrics={"event_output": "accuracy", "sent_output": "accuracy"} # Corrected metrics format
    )
    return model

tuner = kt.Hyperband(build_model, objective="val_loss", max_epochs=30, factor=3)
tuner.search([train_ids, train_mask], [y_train_event, y_train_sent], validation_data=([val_ids,val_mask],[y_val_event,y_val_sent]))
best_hp = tuner.get_best_hyperparameters(1)[0]

print("Best HPs:", best_hp.values)

# ------------------------
# Train Final Model with Best HPs
# ------------------------
model = build_model(best_hp)
history = model.fit([train_ids, train_mask], [y_train_event, y_train_sent],
          validation_data=([val_ids,val_mask],[y_val_event,y_val_sent]),
          epochs=EPOCHS, batch_size=BATCH_SIZE)

# ------------------------
# Evaluate
# ------------------------
preds = model.predict([test_ids, test_mask])
event_preds = np.argmax(preds[0], axis=1)
sent_preds = np.argmax(preds[1], axis=1)

print_report(y_test_event, event_preds, le_event, "Proposed Event")
print_report(y_test_sent, sent_preds, le_sent, "Proposed Sentiment")

print("Event Metrics:", compute_metrics(y_test_event, event_preds))
print("Sentiment Metrics:", compute_metrics(y_test_sent, sent_preds))